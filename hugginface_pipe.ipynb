{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader"
      ],
      "metadata": {
        "id": "6bIzIDpgKl_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjKY6ij-NMf0",
        "outputId": "b1ae6a17-9985-478a-9fc9-14fdaaa22741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-5.5.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Downloading pypdf-5.5.0-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.4/303.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AC97evw3R_XO",
        "outputId": "98f014f2-ac3c-42df-937b-b329d5ac9e1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(texts[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "pfpHMim5SHHd",
        "outputId": "50fa4aef-5f6c-4f61-866b-47be22975ed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langchain_core.documents.base.Document"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.documents.base.Document</b><br/>def __init__(page_content: str, **kwargs: Any) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/langchain_core/documents/base.py</a>Class for storing a piece of text and associated metadata.\n",
              "\n",
              "Example:\n",
              "\n",
              "    .. code-block:: python\n",
              "\n",
              "        from langchain_core.documents import Document\n",
              "\n",
              "        document = Document(\n",
              "            page_content=&quot;Hello, world!&quot;,\n",
              "            metadata={&quot;source&quot;: &quot;https://example.com&quot;}\n",
              "        )</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 255);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# with open(\"state_of_the_union.txt\") as f:\n",
        "#     state_of_the_union = f.read()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size=512,\n",
        "    chunk_overlap=100,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")\n",
        "\n",
        "texts = text_splitter.create_documents([slp])\n",
        "# print(\"Chunk 2: \", texts[1].page_content)\n",
        "# print(\"Chunk 3: \", texts[2].page_content)"
      ],
      "metadata": {
        "id": "YJGDrt5bQm63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [Document(page_content=page.page_content, metadata={'page':page.metadata[\"page_label\"],\"source\":page.metadata[\"source\"],\"user\":user}) for page in PyPDFLoader(uploaded_file).lazy_load() ]"
      ],
      "metadata": {
        "id": "Phskjv2rVrRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "# from langchain_document_loaders import PyPDFLoader\n",
        "\n",
        "# Assuming 'uploaded_file' is the path or file-like object of your uploaded PDF\n",
        "# uploaded_file = \"your_uploaded_file.pdf\"  # Replace with your actual file\n",
        "\n",
        "# Load the PDF content lazily\n",
        "docs = [Document(page_content=page.page_content, metadata={'page': page.metadata[\"page_label\"], \"source\": page.metadata[\"source\"], \"user\": \"your_user\"}) for page in PyPDFLoader(uploaded_file).lazy_load()]\n",
        "\n",
        "# 1. Combine the content of all pages\n",
        "combined_content = \"\"\n",
        "for doc in docs:\n",
        "    combined_content += doc.page_content + \"\\n\\n\"  # Add some separation between pages\n",
        "\n",
        "# 2. Initialize the RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=512,\n",
        "    chunk_overlap=100,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")\n",
        "\n",
        "# 3. Split the combined content into chunks\n",
        "texts = text_splitter.create_documents([combined_content])"
      ],
      "metadata": {
        "id": "MUQc1jkYWtkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs=[]\n",
        "for i in PyPDFLoader(uploaded_file).lazy_load():\n",
        "  l=0\n",
        "  for j in text_splitter.create_documents([i.page_content]):\n",
        "    docs.append(Document(page_content=j.page_content, metadata={\"section\":l,'page': i.metadata[\"page_label\"], \"source\": i.metadata[\"source\"], \"user\": \"your_user\"}))\n",
        "    l+=1\n",
        "  #  text_splitter.create_documents([combined_content])"
      ],
      "metadata": {
        "id": "bhXQjB1fYKut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwQwVKVaZ06F",
        "outputId": "d16eafcc-1e7d-4293-8383-5c8083096cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'section': 0, 'page': '1', 'source': 'pyspark.pdf', 'user': 'your_user'}, page_content=\"[ \\nE T L \\np r o c e s s e s \\nu s i n g \\nP y S p a r k \\n] \\n# \\nQ u i c k \\nS u m m a r y \\n 1.EnvironmentSetupandSparkSessionCreation\\n●\\nInstall\\nPySpark\\n: pipinstallpyspark●\\nStart\\na\\nSparkSession\\n: frompyspark.sqlimportSparkSession;spark=SparkSession.builder.appName('ETLProcess').getOrCreate()\\n2.DataExtraction\\n●\\nRead\\nData\\nfrom\\nCSV\\n: df= spark.read.csv('path/to/csv',inferSchema=True,header=True)●\\nRead\\nData\\nfrom\\nJSON\\n: df= spark.read.json('path/to/json')●\\nRead\\nData\\nfrom\\nParquet\"),\n",
              " Document(metadata={'section': 1, 'page': '1', 'source': 'pyspark.pdf', 'user': 'your_user'}, page_content='Read\\nData\\nfrom\\nJSON\\n: df= spark.read.json(\\'path/to/json\\')●\\nRead\\nData\\nfrom\\nParquet\\n: df= spark.read.parquet(\\'path/to/parquet\\')●\\nRead\\nData\\nfrom\\na\\nDatabase\\n: df=spark.read.format(\"jdbc\").option(\"url\",jdbc_url).option(\"dbtable\",\"table_name\").option(\"user\",\"username\").option(\"password\",\"password\").load()\\n3.DataTransformation\\n●\\nSelecting\\nColumns\\n: df.select(\\'column1\\',\\'column2\\')●\\nFiltering\\nData\\n: df.filter(df[\\'column\\']> value)●\\nAdding\\nNew\\nColumns\\n: df.withColumn(\\'new_column\\',df[\\'column\\']+10)●\\nRenaming\\nColumns'),\n",
              " Document(metadata={'section': 2, 'page': '1', 'source': 'pyspark.pdf', 'user': 'your_user'}, page_content=\"Adding\\nNew\\nColumns\\n: df.withColumn('new_column',df['column']+10)●\\nRenaming\\nColumns\\n: df.withColumnRenamed('old_name','new_name')●\\nGrouping\\nand\\nAggregating\\nData\\n: df.groupBy('column').agg({'column2':'sum'})●\\nJoining\\nDataFrames\\n: df1.join(df2,df1['id']==df2['id'])●\\nSorting\\nData\\n: df.orderBy(df['column'].desc())●\\nRemoving\\nDuplicates\\n: df.dropDuplicates()\\n4.HandlingMissingValues\\n●\\nDropping\\nRows\\nwith\\nMissing\\nValues\\n: df.na.drop()●\\nFilling\\nMissing\\nValues\\n: df.na.fill(value)●\\nReplacing\\nValues\"),\n",
              " Document(metadata={'section': 3, 'page': '1', 'source': 'pyspark.pdf', 'user': 'your_user'}, page_content=\"with\\nMissing\\nValues\\n: df.na.drop()●\\nFilling\\nMissing\\nValues\\n: df.na.fill(value)●\\nReplacing\\nValues\\n: df.na.replace(['old_value'],['new_value'])\\nBy:\\nWaleed\\nMousa\"),\n",
              " Document(metadata={'section': 0, 'page': '2', 'source': 'pyspark.pdf', 'user': 'your_user'}, page_content=\"5.DataTypeConversion\\n●\\nChanging\\nColumn\\nTypes\\n: df.withColumn('column',df['column'].cast('new_type'))●\\nParsing\\nDates\\n: frompyspark.sql.functionsimportto_date;df.withColumn('date',to_date(df['date_string']))\\n6.AdvancedDataManipulations\\n●\\nUsing\\nSQL\\nQueries\\n: df.createOrReplaceTempView('table');spark.sql('SELECT*FROMtableWHEREcolumn> value')●\\nWindow\\nFunctions\"),\n",
              " Document(metadata={'section': 1, 'page': '2', 'source': 'pyspark.pdf', 'user': 'your_user'}, page_content=\"Window\\nFunctions\\n: frompyspark.sql.windowimportWindow;frompyspark.sql.functionsimportrow_number;df.withColumn('row',row_number().over(Window.partitionBy('column').orderBy('other_column')))●\\nPivot\\nTables\\n:df.groupBy('column').pivot('pivot_column').agg({'column2':'sum'})\\n7.DataLoading\\n●\\nWriting\\nto\\nCSV\\n: df.write.csv('path/to/output')●\\nWriting\\nto\\nJSON\\n: df.write.json('path/to/output')●\\nWriting\\nto\\nParquet\\n: df.write.parquet('path/to/output')●\\nWriting\\nto\\na\\nDatabase\"),\n",
              " Document(metadata={'section': 2, 'page': '2', 'source': 'pyspark.pdf', 'user': 'your_user'}, page_content='Writing\\nto\\nParquet\\n: df.write.parquet(\\'path/to/output\\')●\\nWriting\\nto\\na\\nDatabase\\n: df.write.format(\"jdbc\").option(\"url\",jdbc_url).option(\"dbtable\",\"table_name\").option(\"user\",\"username\").option(\"password\",\"password\").save()\\n8.PerformanceTuning\\n●\\nCaching\\nData\\n: df.cache()●\\nBroadcasting\\na\\nDataFrame\\nfor\\nJoin\\nOptimization\\n: frompyspark.sql.functionsimportbroadcast;df1.join(broadcast(df2),df1[\\'id\\']==df2[\\'id\\'])●\\nRepartitioning\\nData\\n: df.repartition(10)●\\nCoalescing\\nPartitions\\n: df.coalesce(1)'),\n",
              " Document(metadata={'section': 3, 'page': '2', 'source': 'pyspark.pdf', 'user': 'your_user'}, page_content='Repartitioning\\nData\\n: df.repartition(10)●\\nCoalescing\\nPartitions\\n: df.coalesce(1)\\n9.DebuggingandErrorHandling\\n●\\nShowing\\nExecution\\nPlan\\n: df.explain() \\nBy:\\nWaleed\\nMousa'),\n",
              " Document(metadata={'section': 0, 'page': '3', 'source': 'pyspark.pdf', 'user': 'your_user'}, page_content=\"●\\nCatching\\nExceptions\\nduring\\nRead\\n:\\nImplement\\ntry-except\\nblocks\\nduring\\ndata\\nreading\\noperations.\\n10.WorkingwithComplexDataTypes\\n●\\nExploding\\nArrays\\n: frompyspark.sql.functionsimportexplode;df.select(explode(df['array_column']))●\\nHandling\\nStruct\\nFields\\n: df.select('struct_column.field1','struct_column.field2')\\n11.CustomTransformationswithUDFs\\n●\\nDeﬁning\\na\\nUDF\\n: frompyspark.sql.functionsimportudf;@udf('return_type')defmy_udf(column):returntransformation●\\nApplying\\nUDF\\non\\nDataFrame\"),\n",
              " Document(metadata={'section': 1, 'page': '3', 'source': 'pyspark.pdf', 'user': 'your_user'}, page_content=\"Applying\\nUDF\\non\\nDataFrame\\n: df.withColumn('new_column',my_udf(df['column']))\\n12.WorkingwithLargeTextData\\n●\\nTokenizing\\nText\\nData\\n: frompyspark.ml.featureimportTokenizer;Tokenizer(inputCol='text_column',outputCol='words').transform(df)●\\nTF-IDF\\non\\nText\\nData\\n: frompyspark.ml.featureimportHashingTF,IDF;HashingTF(inputCol='words',outputCol='rawFeatures').transform(df)\\n13.MachineLearningIntegration\\n●\\nUsing\\nMLlib\\nfor\\nPredictive\\nModeling\\n:\\nBuilding\\nand\\ntraining\\nmachine\\nlearning\\nmodels\\nusing\\nPySpark's\\nMLlib.●\\nModel\"),\n",
              " Document(metadata={'section': 2, 'page': '3', 'source': 'pyspark.pdf', 'user': 'your_user'}, page_content=\"Predictive\\nModeling\\n:\\nBuilding\\nand\\ntraining\\nmachine\\nlearning\\nmodels\\nusing\\nPySpark's\\nMLlib.●\\nModel\\nEvaluation\\nand\\nTuning\\n: frompyspark.ml.evaluationimportMulticlassClassificationEvaluator;MulticlassClassificationEvaluator().evaluate(predictions)\\n14.StreamProcessing\\n●\\nReading\\nfrom\\na\\nStream\\n: dfStream=spark.readStream.format('source').load()●\\nWriting\\nto\\na\\nStream\\n: dfStream.writeStream.format('console').start()\\nBy:\\nWaleed\\nMousa\"),\n",
              " Document(metadata={'section': 0, 'page': '4', 'source': 'pyspark.pdf', 'user': 'your_user'}, page_content=\"15.AdvancedDataExtraction\\n●\\nReading\\nfrom\\nMultiple\\nSources\\n: df=spark.read.format('format').option('option','value').load(['path1','path2'])●\\nIncremental\\nData\\nLoading\\n:\\nImplementing\\nlogic\\nto\\nload\\ndata\\nincrementally,\\nbased\\non\\ntimestamps\\nor\\nlog\\ntables.\\n16.ComplexDataTransformations\\n●\\nNested\\nJSON\\nParsing\\n: frompyspark.sql.functionsimportjson_tuple;df.select(json_tuple('json_column','field1','field2'))●\\nApplying\\nMap-Type\\nTransformations\\n:\\nUsing map\\nfunctions\\nto\\ntransform\\nkey-value\\npair\\ndata.\"),\n",
              " Document(metadata={'section': 1, 'page': '4', 'source': 'pyspark.pdf', 'user': 'your_user'}, page_content=\"Applying\\nMap-Type\\nTransformations\\n:\\nUsing map\\nfunctions\\nto\\ntransform\\nkey-value\\npair\\ndata.\\n17.AdvancedJoinsandSetOperations\\n●\\nBroadcast\\nJoin\\nwith\\nLarge\\nand\\nSmall\\nDataFrames\\n:\\nUtilizingbroadcast\\nfor\\nefﬁcient\\njoins.●\\nSet\\nOperations\\n(Union,\\nIntersect,\\nExcept)\\n:\\nPerforming\\nset\\noperations\\nlike df1.union(df2)\\n, df1.intersect(df2)\\n,df1.except(df2)\\n.\\n18.DataAggregationandSummarization\\n●\\nComplex\\nAggregations\\n: df.groupBy('group_col').agg({'num_col1':'sum','num_col2':'avg'})●\\nRollup\\nand\\nCube\\nfor\\nMulti-Dimensional\"),\n",
              " Document(metadata={'section': 2, 'page': '4', 'source': 'pyspark.pdf', 'user': 'your_user'}, page_content=\"Rollup\\nand\\nCube\\nfor\\nMulti-Dimensional\\nAggregation\\n:df.rollup('col1','col2').sum()\\n, df.cube('col1','col2').mean()\\n19.AdvancedDataFiltering\\n●\\nFiltering\\nwith\\nComplex\\nConditions\\n: df.filter((df['col1']> value)&(df['col2']<other_value))●\\nUsing\\nColumn\\nExpressions\\n: frompyspark.sqlimportfunctionsasF;df.filter(F.col('col1').like('%pattern%'))\\nBy:\\nWaleed\\nMousa\"),\n",
              " Document(metadata={'section': 0, 'page': '5', 'source': 'pyspark.pdf', 'user': 'your_user'}, page_content=\"20.WorkingwithDatesandTimes\\n●\\nDate\\nArithmetic\\n: df.withColumn('new_date',F.col('date_col')+F.expr('interval1 day'))●\\nDate\\nTruncation\\nand\\nFormatting\\n: df.withColumn('month',F.trunc('month','date_col'))\\n21.HandlingNestedandComplexStructures\\n●\\nWorking\\nwith\\nArrays\\nand\\nMaps\\n: df.select(F.explode('array_col'))\\n,df.select(F.col('map_col')['key'])●\\nFlattening\\nNested\\nStructures\\n: df.selectExpr('struct_col.*')\\n22.TextProcessingandNaturalLanguageProcessing\\n●\\nRegular\\nExpressions\\nfor\\nText\\nData\"),\n",
              " Document(metadata={'section': 1, 'page': '5', 'source': 'pyspark.pdf', 'user': 'your_user'}, page_content=\"22.TextProcessingandNaturalLanguageProcessing\\n●\\nRegular\\nExpressions\\nfor\\nText\\nData\\n: df.withColumn('extracted',F.regexp_extract('text_col','(pattern)',1))●\\nSentiment\\nAnalysis\\non\\nText\\nData\\n:\\nUsing\\nNLP\\nlibraries\\nto\\nperform\\nsentiment\\nanalysis\\non\\ntextual\\ncolumns.\\n23.AdvancedWindowFunctions\\n●\\nWindow\\nFunctions\\nfor\\nRunning\\nTotals\\nand\\nMoving\\nAverages\\n: frompyspark.sql.windowimportWindow;windowSpec=Window.partitionBy('group_col').orderBy('date_col');df.withColumn('cumulative_sum',F.sum('num_col').over(windowSpec))●\"),\n",
              " Document(metadata={'section': 2, 'page': '5', 'source': 'pyspark.pdf', 'user': 'your_user'}, page_content=\"Ranking\\nand\\nRow\\nNumbering\\n: df.withColumn('rank',F.rank().over(windowSpec))\\n24.DataQualityandConsistencyChecks\\n●\\nData\\nProﬁling\\nfor\\nQuality\\nAssessment\\n:\\nGenerating\\nstatistics\\nfor\\neach\\ncolumn\\nto\\nassess\\ndata\\nquality.●\\nConsistency\\nChecks\\nAcross\\nDataFrames\\n:\\nComparing\\nschema\\nand\\nrow\\ncounts\\nbetween\\nDataFrames\\nfor\\nconsistency.\\n25.ETLPipelineMonitoringandLogging\\nBy:\\nWaleed\\nMousa\"),\n",
              " Document(metadata={'section': 0, 'page': '6', 'source': 'pyspark.pdf', 'user': 'your_user'}, page_content=\"●\\nImplementing\\nLogging\\nin\\nPySpark\\nJobs\\n:\\nUsing\\nPython's\\nlogging\\nmodule\\nto\\nlog\\nETL\\nprocess\\nsteps.●\\nMonitoring\\nPerformance\\nMetrics\\n:\\nTracking\\nexecution\\ntime\\nand\\nresource\\nutilization\\nof\\nETL\\njobs.\\n26.ETLWorkflowSchedulingandAutomation\\n●\\nIntegration\\nwith\\nWorkﬂow\\nManagement\\nTools\\n:\\nAutomating\\nPySpark\\nETL\\nscripts\\nusing\\ntools\\nlike\\nApache\\nAirﬂow\\nor\\nLuigi.●\\nScheduling\\nPeriodic\\nETL\\nJobs\\n:\\nSetting\\nup\\ncron\\njobs\\nor\\nusing\\nscheduler\\nservices\\nfor\\nregular\\nETL\\ntasks.\\n27.DataPartitioningandBucketing\\n●\\nPartitioning\\nData\\nfor\"),\n",
              " Document(metadata={'section': 1, 'page': '6', 'source': 'pyspark.pdf', 'user': 'your_user'}, page_content=\"scheduler\\nservices\\nfor\\nregular\\nETL\\ntasks.\\n27.DataPartitioningandBucketing\\n●\\nPartitioning\\nData\\nfor\\nEfﬁcient\\nStorage\\n:df.write.partitionBy('date_col').parquet('path/to/output')●\\nBucketing\\nData\\nfor\\nOptimized\\nQuery\\nPerformance\\n:df.write.bucketBy(42,'key_col').sortBy('sort_col').saveAsTable('bucketed_table')\\n28.AdvancedSparkSQLTechniques\\n●\\nUsing\\nTemporary\\nViews\\nfor\\nSQL\\nQueries\\n:df.createOrReplaceTempView('temp_view');spark.sql('SELECT*FROMtemp_viewWHEREcol> value')●\\nComplex\\nSQL\\nQueries\\nfor\\nData\\nTransformation\\n:\"),\n",
              " Document(metadata={'section': 2, 'page': '6', 'source': 'pyspark.pdf', 'user': 'your_user'}, page_content=\"Complex\\nSQL\\nQueries\\nfor\\nData\\nTransformation\\n:\\nUtilizing\\nadvanced\\nSQL\\nsyntax\\nfor\\ncomplex\\ndata\\ntransformations.\\n29.MachineLearningPipelines\\n●\\nCreating\\nand\\nTuning\\nML\\nPipelines\\n:\\nUsing\\nPySpark's\\nMLlib\\nfor\\nbuilding\\nand\\ntuning\\nmachine\\nlearning\\npipelines.●\\nFeature\\nEngineering\\nin\\nML\\nPipelines\\n:\\nImplementing\\nfeature\\ntransformers\\nand\\nselectors\\nwithin\\nML\\npipelines.\\n30.IntegrationwithOtherBigDataTools\\nBy:\\nWaleed\\nMousa\"),\n",
              " Document(metadata={'section': 0, 'page': '7', 'source': 'pyspark.pdf', 'user': 'your_user'}, page_content='●\\nReading\\nand\\nWriting\\nData\\nto\\nHDFS\\n:\\nAccessing\\nHadoop\\nDistributed\\nFile\\nSystem\\n(HDFS)\\nfor\\ndata\\nstorage\\nand\\nretrieval.●\\nInterfacing\\nwith\\nKafka\\nfor\\nReal-Time\\nData\\nProcessing\\n:\\nConnecting\\nto\\nApache\\nKafka\\nfor\\nstream\\nprocessing\\ntasks.\\n31.Cloud-SpecificPySparkOperations\\n●\\nUtilizing\\nCloud-Speciﬁc\\nStorage\\nOptions\\n:\\nLeveraging\\nAWS\\nS3,\\nAzure\\nBlob\\nStorage,\\nor\\nGCP\\nStorage\\nin\\nPySpark.●\\nCloud-Based\\nData\\nProcessing\\nServices\\nIntegration\\n:\\nUsing\\nservices\\nlike\\nAWS\\nGlue\\nor\\nAzure\\nSynapse\\nfor\\nETL\\nprocesses.'),\n",
              " Document(metadata={'section': 1, 'page': '7', 'source': 'pyspark.pdf', 'user': 'your_user'}, page_content='Processing\\nServices\\nIntegration\\n:\\nUsing\\nservices\\nlike\\nAWS\\nGlue\\nor\\nAzure\\nSynapse\\nfor\\nETL\\nprocesses.\\n32.SecurityandComplianceinETL\\n●\\nImplementing\\nData\\nEncryption\\nand\\nSecurity\\n:\\nSecuring\\ndata\\nat\\nrest\\nand\\nin\\ntransit\\nduring\\nETL\\nprocesses.●\\nCompliance\\nwith\\nData\\nProtection\\nRegulations\\n:\\nAdhering\\nto\\nGDPR,\\nHIPAA,\\nor\\nother\\nregulations\\nin\\ndata\\nprocessing.\\n33.OptimizingETLProcessesforScalability\\n●\\nDynamic\\nResource\\nAllocation\\nfor\\nETL\\nJobs\\n:\\nAdjusting\\nSpark\\nconﬁgurations\\nfor\\noptimal\\nresource\\nusage.●\\nBest\\nPractices\\nfor'),\n",
              " Document(metadata={'section': 2, 'page': '7', 'source': 'pyspark.pdf', 'user': 'your_user'}, page_content='for\\nETL\\nJobs\\n:\\nAdjusting\\nSpark\\nconﬁgurations\\nfor\\noptimal\\nresource\\nusage.●\\nBest\\nPractices\\nfor\\nScaling\\nETL\\nProcesses\\n:\\nTechniques\\nfor\\nscaling\\nETL\\npipelines\\nto\\nhandle\\ngrowing\\ndata\\nvolumes.\\nBy:\\nWaleed\\nMousa')]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in texts:\n",
        "  print(i.page_content,end=\"----------------\\n\\n\\n\\n----------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fo-JYEutW7-_",
        "outputId": "36908ed9-2295-4bcd-9afd-d1c83c74ca00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ \n",
            "E T L \n",
            "p r o c e s s e s \n",
            "u s i n g \n",
            "P y S p a r k \n",
            "] \n",
            "# \n",
            "Q u i c k \n",
            "S u m m a r y \n",
            " 1.EnvironmentSetupandSparkSessionCreation\n",
            "●\n",
            "Install\n",
            "PySpark\n",
            ": pipinstallpyspark●\n",
            "Start\n",
            "a\n",
            "SparkSession\n",
            ": frompyspark.sqlimportSparkSession;spark=SparkSession.builder.appName('ETLProcess').getOrCreate()\n",
            "2.DataExtraction\n",
            "●\n",
            "Read\n",
            "Data\n",
            "from\n",
            "CSV\n",
            ": df= spark.read.csv('path/to/csv',inferSchema=True,header=True)●\n",
            "Read\n",
            "Data\n",
            "from\n",
            "JSON\n",
            ": df= spark.read.json('path/to/json')●\n",
            "Read\n",
            "Data\n",
            "from\n",
            "Parquet----------------\n",
            "\n",
            "\n",
            "\n",
            "----------------------Read\n",
            "Data\n",
            "from\n",
            "JSON\n",
            ": df= spark.read.json('path/to/json')●\n",
            "Read\n",
            "Data\n",
            "from\n",
            "Parquet\n",
            ": df= spark.read.parquet('path/to/parquet')●\n",
            "Read\n",
            "Data\n",
            "from\n",
            "a\n",
            "Database\n",
            ": df=spark.read.format(\"jdbc\").option(\"url\",jdbc_url).option(\"dbtable\",\"table_name\").option(\"user\",\"username\").option(\"password\",\"password\").load()\n",
            "3.DataTransformation\n",
            "●\n",
            "Selecting\n",
            "Columns\n",
            ": df.select('column1','column2')●\n",
            "Filtering\n",
            "Data\n",
            ": df.filter(df['column']> value)●\n",
            "Adding\n",
            "New\n",
            "Columns\n",
            ": df.withColumn('new_column',df['column']+10)●\n",
            "Renaming\n",
            "Columns----------------\n",
            "\n",
            "\n",
            "\n",
            "----------------------Adding\n",
            "New\n",
            "Columns\n",
            ": df.withColumn('new_column',df['column']+10)●\n",
            "Renaming\n",
            "Columns\n",
            ": df.withColumnRenamed('old_name','new_name')●\n",
            "Grouping\n",
            "and\n",
            "Aggregating\n",
            "Data\n",
            ": df.groupBy('column').agg({'column2':'sum'})●\n",
            "Joining\n",
            "DataFrames\n",
            ": df1.join(df2,df1['id']==df2['id'])●\n",
            "Sorting\n",
            "Data\n",
            ": df.orderBy(df['column'].desc())●\n",
            "Removing\n",
            "Duplicates\n",
            ": df.dropDuplicates()\n",
            "4.HandlingMissingValues\n",
            "●\n",
            "Dropping\n",
            "Rows\n",
            "with\n",
            "Missing\n",
            "Values\n",
            ": df.na.drop()●\n",
            "Filling\n",
            "Missing\n",
            "Values\n",
            ": df.na.fill(value)●\n",
            "Replacing\n",
            "Values----------------\n",
            "\n",
            "\n",
            "\n",
            "----------------------with\n",
            "Missing\n",
            "Values\n",
            ": df.na.drop()●\n",
            "Filling\n",
            "Missing\n",
            "Values\n",
            ": df.na.fill(value)●\n",
            "Replacing\n",
            "Values\n",
            ": df.na.replace(['old_value'],['new_value'])\n",
            "By:\n",
            "Waleed\n",
            "Mousa----------------\n",
            "\n",
            "\n",
            "\n",
            "----------------------5.DataTypeConversion\n",
            "●\n",
            "Changing\n",
            "Column\n",
            "Types\n",
            ": df.withColumn('column',df['column'].cast('new_type'))●\n",
            "Parsing\n",
            "Dates\n",
            ": frompyspark.sql.functionsimportto_date;df.withColumn('date',to_date(df['date_string']))\n",
            "6.AdvancedDataManipulations\n",
            "●\n",
            "Using\n",
            "SQL\n",
            "Queries\n",
            ": df.createOrReplaceTempView('table');spark.sql('SELECT*FROMtableWHEREcolumn> value')●\n",
            "Window\n",
            "Functions----------------\n",
            "\n",
            "\n",
            "\n",
            "----------------------Window\n",
            "Functions\n",
            ": frompyspark.sql.windowimportWindow;frompyspark.sql.functionsimportrow_number;df.withColumn('row',row_number().over(Window.partitionBy('column').orderBy('other_column')))●\n",
            "Pivot\n",
            "Tables\n",
            ":df.groupBy('column').pivot('pivot_column').agg({'column2':'sum'})\n",
            "7.DataLoading\n",
            "●\n",
            "Writing\n",
            "to\n",
            "CSV\n",
            ": df.write.csv('path/to/output')●\n",
            "Writing\n",
            "to\n",
            "JSON\n",
            ": df.write.json('path/to/output')●\n",
            "Writing\n",
            "to\n",
            "Parquet\n",
            ": df.write.parquet('path/to/output')●\n",
            "Writing\n",
            "to\n",
            "a\n",
            "Database----------------\n",
            "\n",
            "\n",
            "\n",
            "----------------------Writing\n",
            "to\n",
            "Parquet\n",
            ": df.write.parquet('path/to/output')●\n",
            "Writing\n",
            "to\n",
            "a\n",
            "Database\n",
            ": df.write.format(\"jdbc\").option(\"url\",jdbc_url).option(\"dbtable\",\"table_name\").option(\"user\",\"username\").option(\"password\",\"password\").save()\n",
            "8.PerformanceTuning\n",
            "●\n",
            "Caching\n",
            "Data\n",
            ": df.cache()●\n",
            "Broadcasting\n",
            "a\n",
            "DataFrame\n",
            "for\n",
            "Join\n",
            "Optimization\n",
            ": frompyspark.sql.functionsimportbroadcast;df1.join(broadcast(df2),df1['id']==df2['id'])●\n",
            "Repartitioning\n",
            "Data\n",
            ": df.repartition(10)●\n",
            "Coalescing\n",
            "Partitions\n",
            ": df.coalesce(1)----------------\n",
            "\n",
            "\n",
            "\n",
            "----------------------Repartitioning\n",
            "Data\n",
            ": df.repartition(10)●\n",
            "Coalescing\n",
            "Partitions\n",
            ": df.coalesce(1)\n",
            "9.DebuggingandErrorHandling\n",
            "●\n",
            "Showing\n",
            "Execution\n",
            "Plan\n",
            ": df.explain() \n",
            "By:\n",
            "Waleed\n",
            "Mousa----------------\n",
            "\n",
            "\n",
            "\n",
            "----------------------●\n",
            "Catching\n",
            "Exceptions\n",
            "during\n",
            "Read\n",
            ":\n",
            "Implement\n",
            "try-except\n",
            "blocks\n",
            "during\n",
            "data\n",
            "reading\n",
            "operations.\n",
            "10.WorkingwithComplexDataTypes\n",
            "●\n",
            "Exploding\n",
            "Arrays\n",
            ": frompyspark.sql.functionsimportexplode;df.select(explode(df['array_column']))●\n",
            "Handling\n",
            "Struct\n",
            "Fields\n",
            ": df.select('struct_column.field1','struct_column.field2')\n",
            "11.CustomTransformationswithUDFs\n",
            "●\n",
            "Deﬁning\n",
            "a\n",
            "UDF\n",
            ": frompyspark.sql.functionsimportudf;@udf('return_type')defmy_udf(column):returntransformation●\n",
            "Applying\n",
            "UDF\n",
            "on\n",
            "DataFrame----------------\n",
            "\n",
            "\n",
            "\n",
            "----------------------Applying\n",
            "UDF\n",
            "on\n",
            "DataFrame\n",
            ": df.withColumn('new_column',my_udf(df['column']))\n",
            "12.WorkingwithLargeTextData\n",
            "●\n",
            "Tokenizing\n",
            "Text\n",
            "Data\n",
            ": frompyspark.ml.featureimportTokenizer;Tokenizer(inputCol='text_column',outputCol='words').transform(df)●\n",
            "TF-IDF\n",
            "on\n",
            "Text\n",
            "Data\n",
            ": frompyspark.ml.featureimportHashingTF,IDF;HashingTF(inputCol='words',outputCol='rawFeatures').transform(df)\n",
            "13.MachineLearningIntegration\n",
            "●\n",
            "Using\n",
            "MLlib\n",
            "for\n",
            "Predictive\n",
            "Modeling\n",
            ":\n",
            "Building\n",
            "and\n",
            "training\n",
            "machine\n",
            "learning\n",
            "models\n",
            "using\n",
            "PySpark's\n",
            "MLlib.●\n",
            "Model----------------\n",
            "\n",
            "\n",
            "\n",
            "----------------------Predictive\n",
            "Modeling\n",
            ":\n",
            "Building\n",
            "and\n",
            "training\n",
            "machine\n",
            "learning\n",
            "models\n",
            "using\n",
            "PySpark's\n",
            "MLlib.●\n",
            "Model\n",
            "Evaluation\n",
            "and\n",
            "Tuning\n",
            ": frompyspark.ml.evaluationimportMulticlassClassificationEvaluator;MulticlassClassificationEvaluator().evaluate(predictions)\n",
            "14.StreamProcessing\n",
            "●\n",
            "Reading\n",
            "from\n",
            "a\n",
            "Stream\n",
            ": dfStream=spark.readStream.format('source').load()●\n",
            "Writing\n",
            "to\n",
            "a\n",
            "Stream\n",
            ": dfStream.writeStream.format('console').start()\n",
            "By:\n",
            "Waleed\n",
            "Mousa----------------\n",
            "\n",
            "\n",
            "\n",
            "----------------------15.AdvancedDataExtraction\n",
            "●\n",
            "Reading\n",
            "from\n",
            "Multiple\n",
            "Sources\n",
            ": df=spark.read.format('format').option('option','value').load(['path1','path2'])●\n",
            "Incremental\n",
            "Data\n",
            "Loading\n",
            ":\n",
            "Implementing\n",
            "logic\n",
            "to\n",
            "load\n",
            "data\n",
            "incrementally,\n",
            "based\n",
            "on\n",
            "timestamps\n",
            "or\n",
            "log\n",
            "tables.\n",
            "16.ComplexDataTransformations\n",
            "●\n",
            "Nested\n",
            "JSON\n",
            "Parsing\n",
            ": frompyspark.sql.functionsimportjson_tuple;df.select(json_tuple('json_column','field1','field2'))●\n",
            "Applying\n",
            "Map-Type\n",
            "Transformations\n",
            ":\n",
            "Using map\n",
            "functions\n",
            "to\n",
            "transform\n",
            "key-value\n",
            "pair\n",
            "data.----------------\n",
            "\n",
            "\n",
            "\n",
            "----------------------Applying\n",
            "Map-Type\n",
            "Transformations\n",
            ":\n",
            "Using map\n",
            "functions\n",
            "to\n",
            "transform\n",
            "key-value\n",
            "pair\n",
            "data.\n",
            "17.AdvancedJoinsandSetOperations\n",
            "●\n",
            "Broadcast\n",
            "Join\n",
            "with\n",
            "Large\n",
            "and\n",
            "Small\n",
            "DataFrames\n",
            ":\n",
            "Utilizingbroadcast\n",
            "for\n",
            "efﬁcient\n",
            "joins.●\n",
            "Set\n",
            "Operations\n",
            "(Union,\n",
            "Intersect,\n",
            "Except)\n",
            ":\n",
            "Performing\n",
            "set\n",
            "operations\n",
            "like df1.union(df2)\n",
            ", df1.intersect(df2)\n",
            ",df1.except(df2)\n",
            ".\n",
            "18.DataAggregationandSummarization\n",
            "●\n",
            "Complex\n",
            "Aggregations\n",
            ": df.groupBy('group_col').agg({'num_col1':'sum','num_col2':'avg'})●\n",
            "Rollup\n",
            "and\n",
            "Cube\n",
            "for\n",
            "Multi-Dimensional----------------\n",
            "\n",
            "\n",
            "\n",
            "----------------------Rollup\n",
            "and\n",
            "Cube\n",
            "for\n",
            "Multi-Dimensional\n",
            "Aggregation\n",
            ":df.rollup('col1','col2').sum()\n",
            ", df.cube('col1','col2').mean()\n",
            "19.AdvancedDataFiltering\n",
            "●\n",
            "Filtering\n",
            "with\n",
            "Complex\n",
            "Conditions\n",
            ": df.filter((df['col1']> value)&(df['col2']<other_value))●\n",
            "Using\n",
            "Column\n",
            "Expressions\n",
            ": frompyspark.sqlimportfunctionsasF;df.filter(F.col('col1').like('%pattern%'))\n",
            "By:\n",
            "Waleed\n",
            "Mousa----------------\n",
            "\n",
            "\n",
            "\n",
            "----------------------20.WorkingwithDatesandTimes\n",
            "●\n",
            "Date\n",
            "Arithmetic\n",
            ": df.withColumn('new_date',F.col('date_col')+F.expr('interval1 day'))●\n",
            "Date\n",
            "Truncation\n",
            "and\n",
            "Formatting\n",
            ": df.withColumn('month',F.trunc('month','date_col'))\n",
            "21.HandlingNestedandComplexStructures\n",
            "●\n",
            "Working\n",
            "with\n",
            "Arrays\n",
            "and\n",
            "Maps\n",
            ": df.select(F.explode('array_col'))\n",
            ",df.select(F.col('map_col')['key'])●\n",
            "Flattening\n",
            "Nested\n",
            "Structures\n",
            ": df.selectExpr('struct_col.*')\n",
            "22.TextProcessingandNaturalLanguageProcessing\n",
            "●\n",
            "Regular\n",
            "Expressions\n",
            "for\n",
            "Text\n",
            "Data----------------\n",
            "\n",
            "\n",
            "\n",
            "----------------------22.TextProcessingandNaturalLanguageProcessing\n",
            "●\n",
            "Regular\n",
            "Expressions\n",
            "for\n",
            "Text\n",
            "Data\n",
            ": df.withColumn('extracted',F.regexp_extract('text_col','(pattern)',1))●\n",
            "Sentiment\n",
            "Analysis\n",
            "on\n",
            "Text\n",
            "Data\n",
            ":\n",
            "Using\n",
            "NLP\n",
            "libraries\n",
            "to\n",
            "perform\n",
            "sentiment\n",
            "analysis\n",
            "on\n",
            "textual\n",
            "columns.\n",
            "23.AdvancedWindowFunctions\n",
            "●\n",
            "Window\n",
            "Functions\n",
            "for\n",
            "Running\n",
            "Totals\n",
            "and\n",
            "Moving\n",
            "Averages\n",
            ": frompyspark.sql.windowimportWindow;windowSpec=Window.partitionBy('group_col').orderBy('date_col');df.withColumn('cumulative_sum',F.sum('num_col').over(windowSpec))●----------------\n",
            "\n",
            "\n",
            "\n",
            "----------------------Ranking\n",
            "and\n",
            "Row\n",
            "Numbering\n",
            ": df.withColumn('rank',F.rank().over(windowSpec))\n",
            "24.DataQualityandConsistencyChecks\n",
            "●\n",
            "Data\n",
            "Proﬁling\n",
            "for\n",
            "Quality\n",
            "Assessment\n",
            ":\n",
            "Generating\n",
            "statistics\n",
            "for\n",
            "each\n",
            "column\n",
            "to\n",
            "assess\n",
            "data\n",
            "quality.●\n",
            "Consistency\n",
            "Checks\n",
            "Across\n",
            "DataFrames\n",
            ":\n",
            "Comparing\n",
            "schema\n",
            "and\n",
            "row\n",
            "counts\n",
            "between\n",
            "DataFrames\n",
            "for\n",
            "consistency.\n",
            "25.ETLPipelineMonitoringandLogging\n",
            "By:\n",
            "Waleed\n",
            "Mousa----------------\n",
            "\n",
            "\n",
            "\n",
            "----------------------●\n",
            "Implementing\n",
            "Logging\n",
            "in\n",
            "PySpark\n",
            "Jobs\n",
            ":\n",
            "Using\n",
            "Python's\n",
            "logging\n",
            "module\n",
            "to\n",
            "log\n",
            "ETL\n",
            "process\n",
            "steps.●\n",
            "Monitoring\n",
            "Performance\n",
            "Metrics\n",
            ":\n",
            "Tracking\n",
            "execution\n",
            "time\n",
            "and\n",
            "resource\n",
            "utilization\n",
            "of\n",
            "ETL\n",
            "jobs.\n",
            "26.ETLWorkflowSchedulingandAutomation\n",
            "●\n",
            "Integration\n",
            "with\n",
            "Workﬂow\n",
            "Management\n",
            "Tools\n",
            ":\n",
            "Automating\n",
            "PySpark\n",
            "ETL\n",
            "scripts\n",
            "using\n",
            "tools\n",
            "like\n",
            "Apache\n",
            "Airﬂow\n",
            "or\n",
            "Luigi.●\n",
            "Scheduling\n",
            "Periodic\n",
            "ETL\n",
            "Jobs\n",
            ":\n",
            "Setting\n",
            "up\n",
            "cron\n",
            "jobs\n",
            "or\n",
            "using\n",
            "scheduler\n",
            "services\n",
            "for\n",
            "regular\n",
            "ETL\n",
            "tasks.\n",
            "27.DataPartitioningandBucketing\n",
            "●\n",
            "Partitioning\n",
            "Data\n",
            "for----------------\n",
            "\n",
            "\n",
            "\n",
            "----------------------scheduler\n",
            "services\n",
            "for\n",
            "regular\n",
            "ETL\n",
            "tasks.\n",
            "27.DataPartitioningandBucketing\n",
            "●\n",
            "Partitioning\n",
            "Data\n",
            "for\n",
            "Efﬁcient\n",
            "Storage\n",
            ":df.write.partitionBy('date_col').parquet('path/to/output')●\n",
            "Bucketing\n",
            "Data\n",
            "for\n",
            "Optimized\n",
            "Query\n",
            "Performance\n",
            ":df.write.bucketBy(42,'key_col').sortBy('sort_col').saveAsTable('bucketed_table')\n",
            "28.AdvancedSparkSQLTechniques\n",
            "●\n",
            "Using\n",
            "Temporary\n",
            "Views\n",
            "for\n",
            "SQL\n",
            "Queries\n",
            ":df.createOrReplaceTempView('temp_view');spark.sql('SELECT*FROMtemp_viewWHEREcol> value')●\n",
            "Complex\n",
            "SQL\n",
            "Queries\n",
            "for\n",
            "Data\n",
            "Transformation\n",
            ":----------------\n",
            "\n",
            "\n",
            "\n",
            "----------------------Complex\n",
            "SQL\n",
            "Queries\n",
            "for\n",
            "Data\n",
            "Transformation\n",
            ":\n",
            "Utilizing\n",
            "advanced\n",
            "SQL\n",
            "syntax\n",
            "for\n",
            "complex\n",
            "data\n",
            "transformations.\n",
            "29.MachineLearningPipelines\n",
            "●\n",
            "Creating\n",
            "and\n",
            "Tuning\n",
            "ML\n",
            "Pipelines\n",
            ":\n",
            "Using\n",
            "PySpark's\n",
            "MLlib\n",
            "for\n",
            "building\n",
            "and\n",
            "tuning\n",
            "machine\n",
            "learning\n",
            "pipelines.●\n",
            "Feature\n",
            "Engineering\n",
            "in\n",
            "ML\n",
            "Pipelines\n",
            ":\n",
            "Implementing\n",
            "feature\n",
            "transformers\n",
            "and\n",
            "selectors\n",
            "within\n",
            "ML\n",
            "pipelines.\n",
            "30.IntegrationwithOtherBigDataTools\n",
            "By:\n",
            "Waleed\n",
            "Mousa----------------\n",
            "\n",
            "\n",
            "\n",
            "----------------------●\n",
            "Reading\n",
            "and\n",
            "Writing\n",
            "Data\n",
            "to\n",
            "HDFS\n",
            ":\n",
            "Accessing\n",
            "Hadoop\n",
            "Distributed\n",
            "File\n",
            "System\n",
            "(HDFS)\n",
            "for\n",
            "data\n",
            "storage\n",
            "and\n",
            "retrieval.●\n",
            "Interfacing\n",
            "with\n",
            "Kafka\n",
            "for\n",
            "Real-Time\n",
            "Data\n",
            "Processing\n",
            ":\n",
            "Connecting\n",
            "to\n",
            "Apache\n",
            "Kafka\n",
            "for\n",
            "stream\n",
            "processing\n",
            "tasks.\n",
            "31.Cloud-SpecificPySparkOperations\n",
            "●\n",
            "Utilizing\n",
            "Cloud-Speciﬁc\n",
            "Storage\n",
            "Options\n",
            ":\n",
            "Leveraging\n",
            "AWS\n",
            "S3,\n",
            "Azure\n",
            "Blob\n",
            "Storage,\n",
            "or\n",
            "GCP\n",
            "Storage\n",
            "in\n",
            "PySpark.●\n",
            "Cloud-Based\n",
            "Data\n",
            "Processing\n",
            "Services\n",
            "Integration\n",
            ":\n",
            "Using\n",
            "services\n",
            "like\n",
            "AWS\n",
            "Glue\n",
            "or\n",
            "Azure\n",
            "Synapse\n",
            "for\n",
            "ETL\n",
            "processes.----------------\n",
            "\n",
            "\n",
            "\n",
            "----------------------Processing\n",
            "Services\n",
            "Integration\n",
            ":\n",
            "Using\n",
            "services\n",
            "like\n",
            "AWS\n",
            "Glue\n",
            "or\n",
            "Azure\n",
            "Synapse\n",
            "for\n",
            "ETL\n",
            "processes.\n",
            "32.SecurityandComplianceinETL\n",
            "●\n",
            "Implementing\n",
            "Data\n",
            "Encryption\n",
            "and\n",
            "Security\n",
            ":\n",
            "Securing\n",
            "data\n",
            "at\n",
            "rest\n",
            "and\n",
            "in\n",
            "transit\n",
            "during\n",
            "ETL\n",
            "processes.●\n",
            "Compliance\n",
            "with\n",
            "Data\n",
            "Protection\n",
            "Regulations\n",
            ":\n",
            "Adhering\n",
            "to\n",
            "GDPR,\n",
            "HIPAA,\n",
            "or\n",
            "other\n",
            "regulations\n",
            "in\n",
            "data\n",
            "processing.\n",
            "33.OptimizingETLProcessesforScalability\n",
            "●\n",
            "Dynamic\n",
            "Resource\n",
            "Allocation\n",
            "for\n",
            "ETL\n",
            "Jobs\n",
            ":\n",
            "Adjusting\n",
            "Spark\n",
            "conﬁgurations\n",
            "for\n",
            "optimal\n",
            "resource\n",
            "usage.●\n",
            "Best\n",
            "Practices\n",
            "for----------------\n",
            "\n",
            "\n",
            "\n",
            "----------------------for\n",
            "ETL\n",
            "Jobs\n",
            ":\n",
            "Adjusting\n",
            "Spark\n",
            "conﬁgurations\n",
            "for\n",
            "optimal\n",
            "resource\n",
            "usage.●\n",
            "Best\n",
            "Practices\n",
            "for\n",
            "Scaling\n",
            "ETL\n",
            "Processes\n",
            ":\n",
            "Techniques\n",
            "for\n",
            "scaling\n",
            "ETL\n",
            "pipelines\n",
            "to\n",
            "handle\n",
            "growing\n",
            "data\n",
            "volumes.\n",
            "By:\n",
            "Waleed\n",
            "Mousa----------------\n",
            "\n",
            "\n",
            "\n",
            "----------------------"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import streamlit as st\n",
        "# from PyPDF2 import PdfReader\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "# uploaded_file = st.file_uploader(\"Upload your PDF\")\n",
        "uploaded_file=\"pyspark.pdf\"\n",
        "user=\"kartik moyade\"\n",
        "if uploaded_file is not None:\n",
        "    docs = [Document(page_content=page.page_content, metadata={'page':page.metadata[\"page_label\"],\"source\":page.metadata[\"source\"],\"user\":user}) for page in PyPDFLoader(uploaded_file).lazy_load() ]"
      ],
      "metadata": {
        "id": "qTFguIy1KYZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "slp=\"\"\"\n",
        "[\n",
        "E T L\n",
        "p r o c e s s e s\n",
        "u s i n g\n",
        "P y S p a r k\n",
        "]\n",
        "#\n",
        "Q u i c k\n",
        "S u m m a r y\n",
        " 1.EnvironmentSetupandSparkSessionCreation\n",
        "●\n",
        "Install\n",
        "PySpark\n",
        ": pipinstallpyspark●\n",
        "Start\n",
        "a\n",
        "SparkSession\n",
        ": frompyspark.sqlimportSparkSession;spark=SparkSession.builder.appName('ETLProcess').getOrCreate()\n",
        "2.DataExtraction\n",
        "●\n",
        "Read\n",
        "Data\n",
        "from\n",
        "CSV\n",
        ": df= spark.read.csv('path/to/csv',inferSchema=True,header=True)●\n",
        "Read\n",
        "Data\n",
        "from\n",
        "JSON\n",
        ": df= spark.read.json('path/to/json')●\n",
        "Read\n",
        "Data\n",
        "from\n",
        "Parquet\n",
        ": df= spark.read.parquet('path/to/parquet')●\n",
        "Read\n",
        "Data\n",
        "from\n",
        "a\n",
        "Database\n",
        ": df=spark.read.format(\"jdbc\").option(\"url\",jdbc_url).option(\"dbtable\",\"table_name\").option(\"user\",\"username\").option(\"password\",\"password\").load()\n",
        "3.DataTransformation\n",
        "●\n",
        "Selecting\n",
        "Columns\n",
        ": df.select('column1','column2')●\n",
        "Filtering\n",
        "Data\n",
        ": df.filter(df['column']> value)●\n",
        "Adding\n",
        "New\n",
        "Columns\n",
        ": df.withColumn('new_column',df['column']+10)●\n",
        "Renaming\n",
        "Columns\n",
        ": df.withColumnRenamed('old_name','new_name')●\n",
        "Grouping\n",
        "and\n",
        "Aggregating\n",
        "Data\n",
        ": df.groupBy('column').agg({'column2':'sum'})●\n",
        "Joining\n",
        "DataFrames\n",
        ": df1.join(df2,df1['id']==df2['id'])●\n",
        "Sorting\n",
        "Data\n",
        ": df.orderBy(df['column'].desc())●\n",
        "Removing\n",
        "Duplicates\n",
        ": df.dropDuplicates()\n",
        "4.HandlingMissingValues\n",
        "●\n",
        "Dropping\n",
        "Rows\n",
        "with\n",
        "Missing\n",
        "Values\n",
        ": df.na.drop()●\n",
        "Filling\n",
        "Missing\n",
        "Values\n",
        ": df.na.fill(value)●\n",
        "Replacing\n",
        "Values\n",
        ": df.na.replace(['old_value'],['new_value'])\n",
        "By:\n",
        "Waleed\n",
        "Mousa\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ESpEFwQKRtU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in PyPDFLoader(uploaded_file).lazy_load():\n",
        "  print(i.page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-6rVGlGO2et",
        "outputId": "6333c5be-2af7-4d9e-d834-f8ca940fde58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ \n",
            "E T L \n",
            "p r o c e s s e s \n",
            "u s i n g \n",
            "P y S p a r k \n",
            "] \n",
            "# \n",
            "Q u i c k \n",
            "S u m m a r y \n",
            " 1.EnvironmentSetupandSparkSessionCreation\n",
            "●\n",
            "Install\n",
            "PySpark\n",
            ": pipinstallpyspark●\n",
            "Start\n",
            "a\n",
            "SparkSession\n",
            ": frompyspark.sqlimportSparkSession;spark=SparkSession.builder.appName('ETLProcess').getOrCreate()\n",
            "2.DataExtraction\n",
            "●\n",
            "Read\n",
            "Data\n",
            "from\n",
            "CSV\n",
            ": df= spark.read.csv('path/to/csv',inferSchema=True,header=True)●\n",
            "Read\n",
            "Data\n",
            "from\n",
            "JSON\n",
            ": df= spark.read.json('path/to/json')●\n",
            "Read\n",
            "Data\n",
            "from\n",
            "Parquet\n",
            ": df= spark.read.parquet('path/to/parquet')●\n",
            "Read\n",
            "Data\n",
            "from\n",
            "a\n",
            "Database\n",
            ": df=spark.read.format(\"jdbc\").option(\"url\",jdbc_url).option(\"dbtable\",\"table_name\").option(\"user\",\"username\").option(\"password\",\"password\").load()\n",
            "3.DataTransformation\n",
            "●\n",
            "Selecting\n",
            "Columns\n",
            ": df.select('column1','column2')●\n",
            "Filtering\n",
            "Data\n",
            ": df.filter(df['column']> value)●\n",
            "Adding\n",
            "New\n",
            "Columns\n",
            ": df.withColumn('new_column',df['column']+10)●\n",
            "Renaming\n",
            "Columns\n",
            ": df.withColumnRenamed('old_name','new_name')●\n",
            "Grouping\n",
            "and\n",
            "Aggregating\n",
            "Data\n",
            ": df.groupBy('column').agg({'column2':'sum'})●\n",
            "Joining\n",
            "DataFrames\n",
            ": df1.join(df2,df1['id']==df2['id'])●\n",
            "Sorting\n",
            "Data\n",
            ": df.orderBy(df['column'].desc())●\n",
            "Removing\n",
            "Duplicates\n",
            ": df.dropDuplicates()\n",
            "4.HandlingMissingValues\n",
            "●\n",
            "Dropping\n",
            "Rows\n",
            "with\n",
            "Missing\n",
            "Values\n",
            ": df.na.drop()●\n",
            "Filling\n",
            "Missing\n",
            "Values\n",
            ": df.na.fill(value)●\n",
            "Replacing\n",
            "Values\n",
            ": df.na.replace(['old_value'],['new_value'])\n",
            "By:\n",
            "Waleed\n",
            "Mousa\n",
            "5.DataTypeConversion\n",
            "●\n",
            "Changing\n",
            "Column\n",
            "Types\n",
            ": df.withColumn('column',df['column'].cast('new_type'))●\n",
            "Parsing\n",
            "Dates\n",
            ": frompyspark.sql.functionsimportto_date;df.withColumn('date',to_date(df['date_string']))\n",
            "6.AdvancedDataManipulations\n",
            "●\n",
            "Using\n",
            "SQL\n",
            "Queries\n",
            ": df.createOrReplaceTempView('table');spark.sql('SELECT*FROMtableWHEREcolumn> value')●\n",
            "Window\n",
            "Functions\n",
            ": frompyspark.sql.windowimportWindow;frompyspark.sql.functionsimportrow_number;df.withColumn('row',row_number().over(Window.partitionBy('column').orderBy('other_column')))●\n",
            "Pivot\n",
            "Tables\n",
            ":df.groupBy('column').pivot('pivot_column').agg({'column2':'sum'})\n",
            "7.DataLoading\n",
            "●\n",
            "Writing\n",
            "to\n",
            "CSV\n",
            ": df.write.csv('path/to/output')●\n",
            "Writing\n",
            "to\n",
            "JSON\n",
            ": df.write.json('path/to/output')●\n",
            "Writing\n",
            "to\n",
            "Parquet\n",
            ": df.write.parquet('path/to/output')●\n",
            "Writing\n",
            "to\n",
            "a\n",
            "Database\n",
            ": df.write.format(\"jdbc\").option(\"url\",jdbc_url).option(\"dbtable\",\"table_name\").option(\"user\",\"username\").option(\"password\",\"password\").save()\n",
            "8.PerformanceTuning\n",
            "●\n",
            "Caching\n",
            "Data\n",
            ": df.cache()●\n",
            "Broadcasting\n",
            "a\n",
            "DataFrame\n",
            "for\n",
            "Join\n",
            "Optimization\n",
            ": frompyspark.sql.functionsimportbroadcast;df1.join(broadcast(df2),df1['id']==df2['id'])●\n",
            "Repartitioning\n",
            "Data\n",
            ": df.repartition(10)●\n",
            "Coalescing\n",
            "Partitions\n",
            ": df.coalesce(1)\n",
            "9.DebuggingandErrorHandling\n",
            "●\n",
            "Showing\n",
            "Execution\n",
            "Plan\n",
            ": df.explain() \n",
            "By:\n",
            "Waleed\n",
            "Mousa\n",
            "●\n",
            "Catching\n",
            "Exceptions\n",
            "during\n",
            "Read\n",
            ":\n",
            "Implement\n",
            "try-except\n",
            "blocks\n",
            "during\n",
            "data\n",
            "reading\n",
            "operations.\n",
            "10.WorkingwithComplexDataTypes\n",
            "●\n",
            "Exploding\n",
            "Arrays\n",
            ": frompyspark.sql.functionsimportexplode;df.select(explode(df['array_column']))●\n",
            "Handling\n",
            "Struct\n",
            "Fields\n",
            ": df.select('struct_column.field1','struct_column.field2')\n",
            "11.CustomTransformationswithUDFs\n",
            "●\n",
            "Deﬁning\n",
            "a\n",
            "UDF\n",
            ": frompyspark.sql.functionsimportudf;@udf('return_type')defmy_udf(column):returntransformation●\n",
            "Applying\n",
            "UDF\n",
            "on\n",
            "DataFrame\n",
            ": df.withColumn('new_column',my_udf(df['column']))\n",
            "12.WorkingwithLargeTextData\n",
            "●\n",
            "Tokenizing\n",
            "Text\n",
            "Data\n",
            ": frompyspark.ml.featureimportTokenizer;Tokenizer(inputCol='text_column',outputCol='words').transform(df)●\n",
            "TF-IDF\n",
            "on\n",
            "Text\n",
            "Data\n",
            ": frompyspark.ml.featureimportHashingTF,IDF;HashingTF(inputCol='words',outputCol='rawFeatures').transform(df)\n",
            "13.MachineLearningIntegration\n",
            "●\n",
            "Using\n",
            "MLlib\n",
            "for\n",
            "Predictive\n",
            "Modeling\n",
            ":\n",
            "Building\n",
            "and\n",
            "training\n",
            "machine\n",
            "learning\n",
            "models\n",
            "using\n",
            "PySpark's\n",
            "MLlib.●\n",
            "Model\n",
            "Evaluation\n",
            "and\n",
            "Tuning\n",
            ": frompyspark.ml.evaluationimportMulticlassClassificationEvaluator;MulticlassClassificationEvaluator().evaluate(predictions)\n",
            "14.StreamProcessing\n",
            "●\n",
            "Reading\n",
            "from\n",
            "a\n",
            "Stream\n",
            ": dfStream=spark.readStream.format('source').load()●\n",
            "Writing\n",
            "to\n",
            "a\n",
            "Stream\n",
            ": dfStream.writeStream.format('console').start()\n",
            "By:\n",
            "Waleed\n",
            "Mousa\n",
            "15.AdvancedDataExtraction\n",
            "●\n",
            "Reading\n",
            "from\n",
            "Multiple\n",
            "Sources\n",
            ": df=spark.read.format('format').option('option','value').load(['path1','path2'])●\n",
            "Incremental\n",
            "Data\n",
            "Loading\n",
            ":\n",
            "Implementing\n",
            "logic\n",
            "to\n",
            "load\n",
            "data\n",
            "incrementally,\n",
            "based\n",
            "on\n",
            "timestamps\n",
            "or\n",
            "log\n",
            "tables.\n",
            "16.ComplexDataTransformations\n",
            "●\n",
            "Nested\n",
            "JSON\n",
            "Parsing\n",
            ": frompyspark.sql.functionsimportjson_tuple;df.select(json_tuple('json_column','field1','field2'))●\n",
            "Applying\n",
            "Map-Type\n",
            "Transformations\n",
            ":\n",
            "Using map\n",
            "functions\n",
            "to\n",
            "transform\n",
            "key-value\n",
            "pair\n",
            "data.\n",
            "17.AdvancedJoinsandSetOperations\n",
            "●\n",
            "Broadcast\n",
            "Join\n",
            "with\n",
            "Large\n",
            "and\n",
            "Small\n",
            "DataFrames\n",
            ":\n",
            "Utilizingbroadcast\n",
            "for\n",
            "efﬁcient\n",
            "joins.●\n",
            "Set\n",
            "Operations\n",
            "(Union,\n",
            "Intersect,\n",
            "Except)\n",
            ":\n",
            "Performing\n",
            "set\n",
            "operations\n",
            "like df1.union(df2)\n",
            ", df1.intersect(df2)\n",
            ",df1.except(df2)\n",
            ".\n",
            "18.DataAggregationandSummarization\n",
            "●\n",
            "Complex\n",
            "Aggregations\n",
            ": df.groupBy('group_col').agg({'num_col1':'sum','num_col2':'avg'})●\n",
            "Rollup\n",
            "and\n",
            "Cube\n",
            "for\n",
            "Multi-Dimensional\n",
            "Aggregation\n",
            ":df.rollup('col1','col2').sum()\n",
            ", df.cube('col1','col2').mean()\n",
            "19.AdvancedDataFiltering\n",
            "●\n",
            "Filtering\n",
            "with\n",
            "Complex\n",
            "Conditions\n",
            ": df.filter((df['col1']> value)&(df['col2']<other_value))●\n",
            "Using\n",
            "Column\n",
            "Expressions\n",
            ": frompyspark.sqlimportfunctionsasF;df.filter(F.col('col1').like('%pattern%'))\n",
            "By:\n",
            "Waleed\n",
            "Mousa\n",
            "20.WorkingwithDatesandTimes\n",
            "●\n",
            "Date\n",
            "Arithmetic\n",
            ": df.withColumn('new_date',F.col('date_col')+F.expr('interval1 day'))●\n",
            "Date\n",
            "Truncation\n",
            "and\n",
            "Formatting\n",
            ": df.withColumn('month',F.trunc('month','date_col'))\n",
            "21.HandlingNestedandComplexStructures\n",
            "●\n",
            "Working\n",
            "with\n",
            "Arrays\n",
            "and\n",
            "Maps\n",
            ": df.select(F.explode('array_col'))\n",
            ",df.select(F.col('map_col')['key'])●\n",
            "Flattening\n",
            "Nested\n",
            "Structures\n",
            ": df.selectExpr('struct_col.*')\n",
            "22.TextProcessingandNaturalLanguageProcessing\n",
            "●\n",
            "Regular\n",
            "Expressions\n",
            "for\n",
            "Text\n",
            "Data\n",
            ": df.withColumn('extracted',F.regexp_extract('text_col','(pattern)',1))●\n",
            "Sentiment\n",
            "Analysis\n",
            "on\n",
            "Text\n",
            "Data\n",
            ":\n",
            "Using\n",
            "NLP\n",
            "libraries\n",
            "to\n",
            "perform\n",
            "sentiment\n",
            "analysis\n",
            "on\n",
            "textual\n",
            "columns.\n",
            "23.AdvancedWindowFunctions\n",
            "●\n",
            "Window\n",
            "Functions\n",
            "for\n",
            "Running\n",
            "Totals\n",
            "and\n",
            "Moving\n",
            "Averages\n",
            ": frompyspark.sql.windowimportWindow;windowSpec=Window.partitionBy('group_col').orderBy('date_col');df.withColumn('cumulative_sum',F.sum('num_col').over(windowSpec))●\n",
            "Ranking\n",
            "and\n",
            "Row\n",
            "Numbering\n",
            ": df.withColumn('rank',F.rank().over(windowSpec))\n",
            "24.DataQualityandConsistencyChecks\n",
            "●\n",
            "Data\n",
            "Proﬁling\n",
            "for\n",
            "Quality\n",
            "Assessment\n",
            ":\n",
            "Generating\n",
            "statistics\n",
            "for\n",
            "each\n",
            "column\n",
            "to\n",
            "assess\n",
            "data\n",
            "quality.●\n",
            "Consistency\n",
            "Checks\n",
            "Across\n",
            "DataFrames\n",
            ":\n",
            "Comparing\n",
            "schema\n",
            "and\n",
            "row\n",
            "counts\n",
            "between\n",
            "DataFrames\n",
            "for\n",
            "consistency.\n",
            "25.ETLPipelineMonitoringandLogging\n",
            "By:\n",
            "Waleed\n",
            "Mousa\n",
            "●\n",
            "Implementing\n",
            "Logging\n",
            "in\n",
            "PySpark\n",
            "Jobs\n",
            ":\n",
            "Using\n",
            "Python's\n",
            "logging\n",
            "module\n",
            "to\n",
            "log\n",
            "ETL\n",
            "process\n",
            "steps.●\n",
            "Monitoring\n",
            "Performance\n",
            "Metrics\n",
            ":\n",
            "Tracking\n",
            "execution\n",
            "time\n",
            "and\n",
            "resource\n",
            "utilization\n",
            "of\n",
            "ETL\n",
            "jobs.\n",
            "26.ETLWorkflowSchedulingandAutomation\n",
            "●\n",
            "Integration\n",
            "with\n",
            "Workﬂow\n",
            "Management\n",
            "Tools\n",
            ":\n",
            "Automating\n",
            "PySpark\n",
            "ETL\n",
            "scripts\n",
            "using\n",
            "tools\n",
            "like\n",
            "Apache\n",
            "Airﬂow\n",
            "or\n",
            "Luigi.●\n",
            "Scheduling\n",
            "Periodic\n",
            "ETL\n",
            "Jobs\n",
            ":\n",
            "Setting\n",
            "up\n",
            "cron\n",
            "jobs\n",
            "or\n",
            "using\n",
            "scheduler\n",
            "services\n",
            "for\n",
            "regular\n",
            "ETL\n",
            "tasks.\n",
            "27.DataPartitioningandBucketing\n",
            "●\n",
            "Partitioning\n",
            "Data\n",
            "for\n",
            "Efﬁcient\n",
            "Storage\n",
            ":df.write.partitionBy('date_col').parquet('path/to/output')●\n",
            "Bucketing\n",
            "Data\n",
            "for\n",
            "Optimized\n",
            "Query\n",
            "Performance\n",
            ":df.write.bucketBy(42,'key_col').sortBy('sort_col').saveAsTable('bucketed_table')\n",
            "28.AdvancedSparkSQLTechniques\n",
            "●\n",
            "Using\n",
            "Temporary\n",
            "Views\n",
            "for\n",
            "SQL\n",
            "Queries\n",
            ":df.createOrReplaceTempView('temp_view');spark.sql('SELECT*FROMtemp_viewWHEREcol> value')●\n",
            "Complex\n",
            "SQL\n",
            "Queries\n",
            "for\n",
            "Data\n",
            "Transformation\n",
            ":\n",
            "Utilizing\n",
            "advanced\n",
            "SQL\n",
            "syntax\n",
            "for\n",
            "complex\n",
            "data\n",
            "transformations.\n",
            "29.MachineLearningPipelines\n",
            "●\n",
            "Creating\n",
            "and\n",
            "Tuning\n",
            "ML\n",
            "Pipelines\n",
            ":\n",
            "Using\n",
            "PySpark's\n",
            "MLlib\n",
            "for\n",
            "building\n",
            "and\n",
            "tuning\n",
            "machine\n",
            "learning\n",
            "pipelines.●\n",
            "Feature\n",
            "Engineering\n",
            "in\n",
            "ML\n",
            "Pipelines\n",
            ":\n",
            "Implementing\n",
            "feature\n",
            "transformers\n",
            "and\n",
            "selectors\n",
            "within\n",
            "ML\n",
            "pipelines.\n",
            "30.IntegrationwithOtherBigDataTools\n",
            "By:\n",
            "Waleed\n",
            "Mousa\n",
            "●\n",
            "Reading\n",
            "and\n",
            "Writing\n",
            "Data\n",
            "to\n",
            "HDFS\n",
            ":\n",
            "Accessing\n",
            "Hadoop\n",
            "Distributed\n",
            "File\n",
            "System\n",
            "(HDFS)\n",
            "for\n",
            "data\n",
            "storage\n",
            "and\n",
            "retrieval.●\n",
            "Interfacing\n",
            "with\n",
            "Kafka\n",
            "for\n",
            "Real-Time\n",
            "Data\n",
            "Processing\n",
            ":\n",
            "Connecting\n",
            "to\n",
            "Apache\n",
            "Kafka\n",
            "for\n",
            "stream\n",
            "processing\n",
            "tasks.\n",
            "31.Cloud-SpecificPySparkOperations\n",
            "●\n",
            "Utilizing\n",
            "Cloud-Speciﬁc\n",
            "Storage\n",
            "Options\n",
            ":\n",
            "Leveraging\n",
            "AWS\n",
            "S3,\n",
            "Azure\n",
            "Blob\n",
            "Storage,\n",
            "or\n",
            "GCP\n",
            "Storage\n",
            "in\n",
            "PySpark.●\n",
            "Cloud-Based\n",
            "Data\n",
            "Processing\n",
            "Services\n",
            "Integration\n",
            ":\n",
            "Using\n",
            "services\n",
            "like\n",
            "AWS\n",
            "Glue\n",
            "or\n",
            "Azure\n",
            "Synapse\n",
            "for\n",
            "ETL\n",
            "processes.\n",
            "32.SecurityandComplianceinETL\n",
            "●\n",
            "Implementing\n",
            "Data\n",
            "Encryption\n",
            "and\n",
            "Security\n",
            ":\n",
            "Securing\n",
            "data\n",
            "at\n",
            "rest\n",
            "and\n",
            "in\n",
            "transit\n",
            "during\n",
            "ETL\n",
            "processes.●\n",
            "Compliance\n",
            "with\n",
            "Data\n",
            "Protection\n",
            "Regulations\n",
            ":\n",
            "Adhering\n",
            "to\n",
            "GDPR,\n",
            "HIPAA,\n",
            "or\n",
            "other\n",
            "regulations\n",
            "in\n",
            "data\n",
            "processing.\n",
            "33.OptimizingETLProcessesforScalability\n",
            "●\n",
            "Dynamic\n",
            "Resource\n",
            "Allocation\n",
            "for\n",
            "ETL\n",
            "Jobs\n",
            ":\n",
            "Adjusting\n",
            "Spark\n",
            "conﬁgurations\n",
            "for\n",
            "optimal\n",
            "resource\n",
            "usage.●\n",
            "Best\n",
            "Practices\n",
            "for\n",
            "Scaling\n",
            "ETL\n",
            "Processes\n",
            ":\n",
            "Techniques\n",
            "for\n",
            "scaling\n",
            "ETL\n",
            "pipelines\n",
            "to\n",
            "handle\n",
            "growing\n",
            "data\n",
            "volumes.\n",
            "By:\n",
            "Waleed\n",
            "Mousa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlTpKd_qNUhA",
        "outputId": "779d715e-a9c4-4a3d-b5a8-f88c99f1655e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ts8lhOrN0_z",
        "outputId": "af400dee-599c-41b4-898b-97ec8d1a45e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ \n",
            "E T L \n",
            "p r o c e s s e s \n",
            "u s i n g \n",
            "P y S p a r k \n",
            "] \n",
            "# \n",
            "Q u i c k \n",
            "S u m m a r y \n",
            " 1.EnvironmentSetupandSparkSessionCreation\n",
            "●\n",
            "Install\n",
            "PySpark\n",
            ": pipinstallpyspark●\n",
            "Start\n",
            "a\n",
            "SparkSession\n",
            ": frompyspark.sqlimportSparkSession;spark=SparkSession.builder.appName('ETLProcess').getOrCreate()\n",
            "2.DataExtraction\n",
            "●\n",
            "Read\n",
            "Data\n",
            "from\n",
            "CSV\n",
            ": df= spark.read.csv('path/to/csv',inferSchema=True,header=True)●\n",
            "Read\n",
            "Data\n",
            "from\n",
            "JSON\n",
            ": df= spark.read.json('path/to/json')●\n",
            "Read\n",
            "Data\n",
            "from\n",
            "Parquet\n",
            ": df= spark.read.parquet('path/to/parquet')●\n",
            "Read\n",
            "Data\n",
            "from\n",
            "a\n",
            "Database\n",
            ": df=spark.read.format(\"jdbc\").option(\"url\",jdbc_url).option(\"dbtable\",\"table_name\").option(\"user\",\"username\").option(\"password\",\"password\").load()\n",
            "3.DataTransformation\n",
            "●\n",
            "Selecting\n",
            "Columns\n",
            ": df.select('column1','column2')●\n",
            "Filtering\n",
            "Data\n",
            ": df.filter(df['column']> value)●\n",
            "Adding\n",
            "New\n",
            "Columns\n",
            ": df.withColumn('new_column',df['column']+10)●\n",
            "Renaming\n",
            "Columns\n",
            ": df.withColumnRenamed('old_name','new_name')●\n",
            "Grouping\n",
            "and\n",
            "Aggregating\n",
            "Data\n",
            ": df.groupBy('column').agg({'column2':'sum'})●\n",
            "Joining\n",
            "DataFrames\n",
            ": df1.join(df2,df1['id']==df2['id'])●\n",
            "Sorting\n",
            "Data\n",
            ": df.orderBy(df['column'].desc())●\n",
            "Removing\n",
            "Duplicates\n",
            ": df.dropDuplicates()\n",
            "4.HandlingMissingValues\n",
            "●\n",
            "Dropping\n",
            "Rows\n",
            "with\n",
            "Missing\n",
            "Values\n",
            ": df.na.drop()●\n",
            "Filling\n",
            "Missing\n",
            "Values\n",
            ": df.na.fill(value)●\n",
            "Replacing\n",
            "Values\n",
            ": df.na.replace(['old_value'],['new_value'])\n",
            "By:\n",
            "Waleed\n",
            "Mousa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FNQqXbCjJBBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxhCHbok5QyJ",
        "outputId": "10f3ef72-3f75-487d-c6d7-606c6688e816"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m2.0/2.5 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.9/437.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q --upgrade langchain\n",
        "!pip install -q --upgrade langchain-community\n",
        "!pip install -q --upgrade langchain-core\n",
        "!pip install -q --upgrade langchain_huggingface\n",
        "!pip install -q --upgrade transformers\n",
        "!pip install -q --upgrade langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xgTwWGjbVSK"
      },
      "outputs": [],
      "source": [
        "import bs4\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Create a WebBaseLoader instance to load documents from web sources\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\n",
        "        \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
        "        \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
        "    ),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "# Load documents from web sources using the loader\n",
        "documents = loader.load()\n",
        "# Initialize a RecursiveCharacterTextSplitter for splitting text into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
        "\n",
        "# Split the documents into chunks using the text_splitter\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "# Let's take a look at the first document\n",
        "docs[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPDmJ3yKbV-1"
      },
      "outputs": [],
      "source": [
        "from langchain_milvus import Milvus\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "vectorstore = Milvus.from_documents(\n",
        "    documents=docs,\n",
        "    embedding=embeddings,\n",
        "    connection_args={\n",
        "        \"uri\": \"./milvus_demo.db\",\n",
        "    },\n",
        "    drop_old=True,  # Drop the old Milvus collection if it exists\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkoX4SSHbWF5"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Initialize the OpenAI language model for response generation\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "# Define the prompt template for generating AI responses\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "Human: You are an AI assistant, and provides answers to questions by using fact based and statistical information when possible.\n",
        "Use the following pieces of information to provide a concise answer to the question enclosed in <question> tags.\n",
        "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "<context>\n",
        "{context}\n",
        "</context>\n",
        "\n",
        "<question>\n",
        "{question}\n",
        "</question>\n",
        "\n",
        "The response should be specific and use statistics or numbers when possible.\n",
        "\n",
        "Assistant:\"\"\"\n",
        "\n",
        "# Create a PromptTemplate instance with the defined template and input variables\n",
        "prompt = PromptTemplate(\n",
        "    template=PROMPT_TEMPLATE, input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "# Convert the vector store to a retriever\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "\n",
        "# Define a function to format the retrieved documents\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrAjrK0hbWNa"
      },
      "outputs": [],
      "source": [
        "# Define the RAG (Retrieval-Augmented Generation) chain for AI response generation\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# rag_chain.get_graph().print_ascii()\n",
        "\n",
        "# Invoke the RAG chain with a specific question and retrieve the response\n",
        "res = rag_chain.invoke(query)\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzyPxsqBbWSF"
      },
      "outputs": [],
      "source": [
        "vectorstore.similarity_search(\n",
        "    \"What is CoT?\",\n",
        "    k=1,\n",
        "    expr=\"source == 'https://lilianweng.github.io/posts/2023-06-23-agent/'\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G063y0oCbWVk"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import ConfigurableField\n",
        "\n",
        "# Define a new retriever with a configurable field for search_kwargs\n",
        "retriever2 = vectorstore.as_retriever().configurable_fields(\n",
        "    search_kwargs=ConfigurableField(\n",
        "        id=\"retriever_search_kwargs\",\n",
        "    )\n",
        ")\n",
        "\n",
        "# Invoke the retriever with a specific search_kwargs which filter the documents by source\n",
        "retriever2.with_config(\n",
        "    configurable={\n",
        "        \"retriever_search_kwargs\": dict(\n",
        "            expr=\"source == 'https://lilianweng.github.io/posts/2023-06-23-agent/'\",\n",
        "            k=1,\n",
        "        )\n",
        "    }\n",
        ").invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRF4IQXZbWY4"
      },
      "outputs": [],
      "source": [
        "rag_chain2 = (\n",
        "    {\"context\": retriever2 | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjCt_zfHb6uJ"
      },
      "outputs": [],
      "source": [
        "rag_chain2.with_config(\n",
        "    configurable={\n",
        "        \"retriever_search_kwargs\": dict(\n",
        "            expr=\"source == 'https://lilianweng.github.io/posts/2023-06-23-agent/'\",\n",
        "        )\n",
        "    }\n",
        ").invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHuU6kqPb7Xx"
      },
      "outputs": [],
      "source": [
        "rag_chain2.with_config(\n",
        "    configurable={\n",
        "        \"retriever_search_kwargs\": dict(\n",
        "            expr=\"source == 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/'\",\n",
        "        )\n",
        "    }\n",
        ").invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyPz-roNbWby"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khM_CEuadqVS"
      },
      "outputs": [],
      "source": [
        "!pip install -q --force langchain langchain-core langchain-community\n",
        "!pip install -qU langchain_milvus\n",
        "!pip install -qU langchain_community pypdf\n",
        "!pip freeze | findstr langchain\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIFXVHP5fq6u"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import getpass\n",
        "from typing import List, TypedDict, Annotated, Sequence, Dict, Optional, Union\n",
        "from operator import itemgetter\n",
        "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain import hub # For pulling agent prompts\n",
        "\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.graph.message import add_messages # Helper to add messages to state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bV3EFXRfv3X"
      },
      "outputs": [],
      "source": [
        "! pip install langchain_community\n",
        "\n",
        "# --- 0. Check/Set API Keys (Optional but good practice) ---\n",
        "def _set_env:\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "from langchain_milvus import Milvus\n",
        "\n",
        "\n",
        "# --- 1. Define State ---\n",
        "# This dictionary holds the application's state, passed between nodes.\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], add_messages] # Chat history\n",
        "    documents: Optional[List[Document]] # Loaded documents for RAG\n",
        "    vectorstore: Optional[Milvus] # The vector store object <-------------- FAISS\n",
        "    retriever: Optional[any] # The retriever object\n",
        "    context: Optional[str] # Context retrieved from RAG or web search\n",
        "    input_type: str # Tracks if input is a file path or query\n",
        "    file_path: Optional[str] # Path to the file to be processed9\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjQMSUm9gPr7"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "# Import the LangChain wrapper\n",
        "from langchain_huggingface import HuggingFacePipeline # Or ChatHuggingFace (see below)\n",
        "\n",
        "# --- Initialize the HF Pipeline ---\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        "    max_new_tokens=256, # Make sure this is enough for the answer\n",
        "    # Removed sampling params for simplicity, add back if needed\n",
        "    # do_sample=True, temperature=0.7, top_k=50, top_p=0.95\n",
        ")\n",
        "\n",
        "tinyllama_chat_template = (\n",
        "    \"{% for message in messages %}\"\n",
        "        \"{% if message['role'] == 'system' %}\"\n",
        "            \"<|system|>\\n{{ message['content'] }}<|end|>\\n\"\n",
        "        \"{% elif message['role'] == 'user' %}\"\n",
        "            \"<|user|>\\n{{ message['content'] }}<|end|>\\n\"\n",
        "        \"{% elif message['role'] == 'assistant' %}\"\n",
        "            \"<|assistant|>\\n{{ message['content'] }}<|end|>\\n\"\n",
        "        \"{% endif %}\"\n",
        "    \"{% endfor %}\"\n",
        "    \"{% if add_generation_prompt %}\"\n",
        "        \"<|assistant|>\\n\"\n",
        "    \"{% endif %}\"\n",
        ")\n",
        "\n",
        "# Set the template on the loaded tokenizer\n",
        "try:\n",
        "    pipe.tokenizer.chat_template = tinyllama_chat_template\n",
        "    print(\"Chat template set successfully on the tokenizer.\")\n",
        "except AttributeError:\n",
        "    print(\"Could not set chat_template. Ensure 'pipe' and 'pipe.tokenizer' are valid.\")\n",
        "    # Handle error appropriately if pipe or tokenizer isn't loaded\n",
        "\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful AI bot. Your name is Carl.\"),\n",
        "    (\"human\", \"{user_input}\"),\n",
        "])\n",
        "\n",
        "# This creates a LangChain PromptValue object\n",
        "prompt_value = template.invoke({\"user_input\": \"Hello, there!\"})\n",
        "\n",
        "\n",
        "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline\n",
        "# from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "# HuggingFacePipeline.model_rebuild()\n",
        "hf = HuggingFacePipeline(pipeline=pipe)\n",
        "# ChatHuggingFace.model_rebuild()\n",
        "# chat_hf_model = ChatHuggingFace(llm=hf)\n",
        "# Load model directly\n",
        "import torch\n",
        "from transformers import AutoModel\n",
        "model = AutoModel.from_pretrained(\"nomic-ai/nomic-embed-text-v1\", trust_remote_code=True)\n",
        "output=model([\"clustering: the quick brown fox\"])\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer(\"nomic-ai/nomic-embed-text-v1\", trust_remote_code=True)\n",
        "sentences = ['clustering: the quick brown fox']\n",
        "embeddings = model.encode(sentences)\n",
        "print(embeddings)\n",
        "\n",
        "embeddings.size\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "model_name = \"nomic-ai/nomic-embed-text-v1\"\n",
        "model_kwargs = {'device': 'cpu','trust_remote_code':True}\n",
        "encode_kwargs = {'normalize_embeddings': False}\n",
        "# hf = HuggingFaceEmbeddings(\n",
        "#     model_name=model_name,\n",
        "#     model_kwargs=model_kwargs,\n",
        "#     encode_kwargs=encode_kwargs\n",
        "# )\n",
        "out2=hf.embed_query(\"clustering: the quick brown fox\")\n",
        "len(out2)\n",
        "\n",
        "# --- 2. Instantiate Components ---\n",
        "llm = ChatHuggingFace(llm=hf) # Or gpt-3.5-turbo\n",
        "embeddings = HuggingFaceEmbeddings( model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs)\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "web_search_tool = TavilySearchResults(max_results=3)\n",
        "tools = [web_search_tool]\n",
        "# tool_executor = ToolExecutor(tools)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UDsQKVFf66-"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# --- 3. Define Nodes (Functions that operate on the state) ---\n",
        "\n",
        "def handle_input_node(state: AgentState):   #\n",
        "    \"\"\"Determines if the user input is a file path or a question.\"\"\"\n",
        "    last_message = state['messages'][-1]\n",
        "    content = last_message.content\n",
        "\n",
        "    # Simple check: Does it look like a path to a PDF or DOCX?\n",
        "    if content.lower().endswith((\".pdf\", \".docx\")) and os.path.exists(content):\n",
        "        print(f\"--- DETECTED FILE PATH: {content} ---\")\n",
        "        return {\"input_type\": \"file\", \"file_path\": content}\n",
        "    else:\n",
        "        print(\"--- DETECTED QUERY ---\")\n",
        "        return {\"input_type\": \"query\", \"file_path\": None}\n",
        "\n",
        "def load_embed_node(state: AgentState):\n",
        "    \"\"\"Loads, splits, embeds document, and updates the vector store.\"\"\"\n",
        "    file_path = state['file_path']\n",
        "    if not file_path:\n",
        "        raise ValueError(\"File path is missing in state for load_embed_node\")\n",
        "\n",
        "    print(f\"--- LOADING & EMBEDDING: {file_path} ---\")\n",
        "    try:\n",
        "        if file_path.lower().endswith(\".pdf\"):\n",
        "            loader = PyPDFLoader(file_path)\n",
        "        elif file_path.lower().endswith(\".docx\"):\n",
        "            loader = Docx2txtLoader(file_path)\n",
        "        else:\n",
        "            # Add more loaders if needed (e.g., UnstructuredFileLoader)\n",
        "             raise ValueError(f\"Unsupported file type: {file_path}\")\n",
        "\n",
        "        docs = loader.load()\n",
        "        split_docs = text_splitter.split_documents(docs)\n",
        "\n",
        "        print(f\"--- SPLIT INTO {len(split_docs)} CHUNKS ---\")\n",
        "\n",
        "        # Get existing vector store from state or create a new one\n",
        "        vectorstore = state.get('vectorstore')\n",
        "\n",
        "        if vectorstore:\n",
        "            print(\"--- ADDING TO EXISTING VECTOR STORE ---\")\n",
        "            vectorstore.add_documents(split_docs)\n",
        "        else:\n",
        "            print(\"--- CREATING NEW VECTOR STORE (FAISS) ---\")\n",
        "            vectorstore = Milvus.from_documents(split_docs\n",
        "            , embeddings\n",
        "            ,connection_args={ \"uri\": \"./milvus_demo.db\",}\n",
        "            ,drop_old=False # Drop the old Milvus collection if it exists\n",
        "            )\n",
        "            # URI = \"http://localhost:19530\"\n",
        "            # vectorstore = Milvus(\n",
        "            #     embedding_function=embeddings,\n",
        "            #     connection_args={\"uri\": URI, \"token\": \"root:Milvus\", \"db_name\": \"milvus_demo\"},\n",
        "            #     index_params={\"index_type\": \"FLAT\", \"metric_type\": \"L2\"},\n",
        "            #     consistency_level=\"Strong\",\n",
        "            #     drop_old=False,  # set to True if seeking to drop the collection with that name if it exists\n",
        "            # )\n",
        "\n",
        "        retriever = vectorstore.as_retriever()\n",
        "\n",
        "        # Respond to the user\n",
        "        ai_message = AIMessage(content=f\"Successfully loaded and embedded '{os.path.basename(file_path)}'. You can now ask questions about it.\")\n",
        "\n",
        "        return {\n",
        "            \"vectorstore\": vectorstore,\n",
        "            \"retriever\": retriever,\n",
        "            \"documents\": split_docs, # Store potentially for reference\n",
        "            \"messages\": [ai_message], # Add AI confirmation message\n",
        "            \"file_path\": None, # Clear the file path after processing\n",
        "            \"input_type\": \"query\" # Reset input type for next turn\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"--- ERROR LOADING/EMBEDDING FILE: {e} ---\")\n",
        "        error_message = AIMessage(content=f\"Sorry, I encountered an error processing the file: {e}\")\n",
        "        return {\"messages\": [error_message], \"file_path\": None, \"input_type\": \"query\"}\n",
        "\n",
        "\n",
        "def route_query_node(state: AgentState):\n",
        "    \"\"\"Routes the query to RAG, Web Search, or direct generation.\"\"\"\n",
        "    print(\"--- ROUTING QUERY ---\")\n",
        "    last_message = state['messages'][-1].content.lower()\n",
        "    retriever = state.get('retriever')\n",
        "\n",
        "    # Simple routing logic:\n",
        "    # 1. If a retriever exists (docs loaded) and query isn't obviously generic, try RAG.\n",
        "    # 2. Otherwise, use the web search agent.\n",
        "    # (More sophisticated routing could involve an LLM call to classify intent)\n",
        "\n",
        "    generic_phrases = [\"what's the weather\", \"who won the game\", \"current time\", \"search for\"]\n",
        "\n",
        "    if retriever and not any(phrase in last_message for phrase in generic_phrases):\n",
        "        print(\"--- ROUTING TO: RAG ---\")\n",
        "        return \"retrieve_docs\"\n",
        "    else:\n",
        "        print(\"--- ROUTING TO: WEB SEARCH AGENT ---\")\n",
        "        return \"web_search_agent\"\n",
        "\n",
        "\n",
        "def retrieve_docs_node(state: AgentState):\n",
        "    \"\"\"Retrieves relevant documents from the vector store.\"\"\"\n",
        "    print(\"--- RETRIEVING DOCUMENTS (RAG) ---\")\n",
        "    retriever = state['retriever']\n",
        "    if not retriever:\n",
        "        # Should not happen if routing is correct, but good to check\n",
        "        return {\"context\": \"Error: No documents loaded to retrieve from.\"}\n",
        "\n",
        "    question = state['messages'][-1].content\n",
        "    retrieved_docs = retriever.with_config(\n",
        "        configurable={\n",
        "            \"retriever_search_kwargs\": dict( # might need to remove\n",
        "                expr=\"source == 'https://lilianweng.github.io/posts/2023-06-23-agent/'\", # <<<<<<<---- CHANGE META FILTER\n",
        "                k=1,\n",
        "            )\n",
        "        }\n",
        "    ).invoke(question)\n",
        "    context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
        "    print(f\"--- RAG CONTEXT RETRIEVED ({len(retrieved_docs)} docs) ---\")\n",
        "    # print(f\"Context Preview: {context[:500]}...\") # Optional: print preview\n",
        "    return {\"context\": context}\n",
        "\n",
        "# --- Web Search Agent Setup ---\n",
        "# Prompt template for the web search agent\n",
        "# Using a standard OpenAI Functions Agent prompt\n",
        "try:\n",
        "    prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
        "except Exception as e:\n",
        "     print(f\"Error pulling prompt from hub: {e}. Using basic fallback.\")\n",
        "     prompt = ChatPromptTemplate.from_messages([\n",
        "         (\"system\", \"You are a helpful assistant with access to a web search tool.\"),\n",
        "         MessagesPlaceholder(variable_name=\"messages\"),\n",
        "         MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "     ])\n",
        "\n",
        "\n",
        "# Bind tools to LLM for function calling\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "# Create the agent runnable\n",
        "web_search_agent_runnable = (\n",
        "    RunnablePassthrough.assign(\n",
        "        agent_scratchpad=lambda x: format_to_openai_function_messages(x[\"intermediate_steps\"])\n",
        "    )\n",
        "    | prompt\n",
        "    | llm_with_tools\n",
        "    # | StrOutputParser() # <---- can add if all go south\n",
        "    # | OpenAIFunctionsAgentOutputParser() # Be specific for clarity <---- CHANGE\n",
        ")\n",
        "\n",
        "\n",
        "class WeatherResponse(BaseModel):\n",
        "    \"\"\"Respond to the user with this\"\"\"\n",
        "\n",
        "    temperature: float = Field(description=\"The temperature in fahrenheit\")\n",
        "    wind_directon: str = Field(\n",
        "        description=\"The direction of the wind in abbreviated form\"\n",
        "    )\n",
        "    wind_speed: float = Field(description=\"The speed of the wind in km/h\")\n",
        "\n",
        "\n",
        "\n",
        "# Define the node for the web search agent\n",
        "def web_search_agent_node(state: AgentState):\n",
        "    \"\"\"Invokes the web search agent.\"\"\"\n",
        "    print(\"--- CALLING WEB SEARCH AGENT ---\")\n",
        "    # Need to import these specifically for the agent node if not already imported broadly\n",
        "    from langchain.agents.format_scratchpad.openai_functions import format_to_openai_function_messages\n",
        "    # from langchain.agents.output_parsers.openai_functions import OpenAIFunctionsAgentOutputParser # <--- CHANGE\n",
        "    from langchain.agents import AgentExecutor # Import AgentExecutor\n",
        "\n",
        "    # Create AgentExecutor dynamically inside the node or pass it if pre-configured\n",
        "    # It's often cleaner to configure agent components outside the node if possible,\n",
        "    # but let's build it here for demonstration if needed.\n",
        "    # Reusing the global llm_with_tools and tool_executor defined earlier.\n",
        "    web_search_agent_runnable1=web_search_agent_runnable.with_structured_output(WeatherResponse)\n",
        "    agent_executor = AgentExecutor(agent=web_search_agent_runnable1, tools=tools, verbose=False) # Set verbose=True for debugging\n",
        "\n",
        "    # Ensure messages are in the correct format for the agent\n",
        "    agent_messages = state['messages']\n",
        "\n",
        "    # Invoke the agent\n",
        "    agent_response = agent_executor.invoke({\"messages\": agent_messages})\n",
        "\n",
        "    # The agent's final answer is in 'output'\n",
        "    # We can potentially store intermediate steps if needed\n",
        "    print(\"--- WEB SEARCH AGENT FINISHED ---\")\n",
        "    # We use the agent's direct output as context for the final generation step\n",
        "    # or let the agent produce the final answer directly.\n",
        "    # For consistency, let's pass its findings as 'context'.\n",
        "    return {\"context\": agent_response.get(\"output\", \"No information found from web search.\")}\n",
        "\n",
        "\n",
        "# --- Final Answer Generation ---\n",
        "rag_prompt_template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant. Answer the user's question based *only* on the following context:\\n\\n{context}\\n\\nIf the context doesn't contain the answer, say you don't have information about that from the provided source.\"),\n",
        "    MessagesPlaceholder(variable_name=\"messages\") # Get the latest question\n",
        "])\n",
        "\n",
        "web_prompt_template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant. Answer the user's question based on the information gathered from your web search:\\n\\n{context}\"),\n",
        "     MessagesPlaceholder(variable_name=\"messages\") # Get the latest question\n",
        "])\n",
        "\n",
        "def generate_response_node(state: AgentState):\n",
        "    \"\"\"Generates the final response using LLM based on context type.\"\"\"\n",
        "    print(\"--- GENERATING FINAL RESPONSE ---\")\n",
        "    context = state.get('context', '') # Get retrieved context\n",
        "    messages = state['messages']\n",
        "    last_node = state.get('last_node_run', None) # Need to track which path was taken\n",
        "\n",
        "    # Select prompt based on which path provided the context\n",
        "    # We need a way to know if context came from RAG or Web Search.\n",
        "    # Let's refine the routing node or add info to state.\n",
        "    # *Correction*: The conditional edge logic already tells us. Let's assume\n",
        "    # if 'retrieve_docs' was the last node before this, use RAG prompt.\n",
        "    # If 'web_search_agent' was last, use web prompt.\n",
        "\n",
        "    # We need a robust way to know the source. Let's assume the router's decision dictates the source.\n",
        "    # This is tricky with current state. A simpler approach: Use a unified prompt.\n",
        "\n",
        "    unified_prompt_template = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"You are a helpful assistant. Answer the user's question based on the provided context below. If the context is empty or doesn't contain the answer, rely on your general knowledge but state that the provided sources didn't have the specific information.\\n\\nContext:\\n{context}\"),\n",
        "        MessagesPlaceholder(variable_name=\"messages\")\n",
        "    ])\n",
        "\n",
        "    # Chain for generation\n",
        "    generation_chain = (\n",
        "        RunnablePassthrough.assign(\n",
        "            # Extract only the last human message for the prompt's \"messages\" placeholder\n",
        "            messages=lambda x: [x['messages'][-1]] if x.get('messages') else [],\n",
        "        )\n",
        "        | unified_prompt_template\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "    # Prepare input for the chain\n",
        "    chain_input = {\"context\": context, \"messages\": messages}\n",
        "\n",
        "    # Generate the final response\n",
        "    response_content = generation_chain.invoke(chain_input)\n",
        "    ai_message = AIMessage(content=response_content)\n",
        "\n",
        "    print(\"--- RESPONSE GENERATED ---\")\n",
        "    return {\"messages\": [ai_message]} # Add final AI response to history\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyj0WCN3f2JD"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --- 4. Build the Graph ---\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"handle_input\", handle_input_node)\n",
        "workflow.add_node(\"load_embed\", load_embed_node)\n",
        "workflow.add_node(\"route_query\", route_query_node)\n",
        "workflow.add_node(\"retrieve_docs\", retrieve_docs_node)\n",
        "workflow.add_node(\"web_search_agent\", web_search_agent_node)\n",
        "workflow.add_node(\"generate_response\", generate_response_node)\n",
        "\n",
        "# Define edges (transitions between nodes)\n",
        "\n",
        "# Start with input handling\n",
        "workflow.set_entry_point(\"handle_input\")\n",
        "\n",
        "# Conditional edge after input handling\n",
        "workflow.add_conditional_edges(\n",
        "    \"handle_input\",\n",
        "    lambda x: x[\"input_type\"], # Check the 'input_type' field in the state\n",
        "    {\n",
        "        \"file\": \"load_embed\",\n",
        "        \"query\": \"route_query\",\n",
        "    }\n",
        ")\n",
        "\n",
        "# After loading/embedding, go back to routing (ready for a query about the doc)\n",
        "# Or maybe just END this cycle and wait for next input? Let's END.\n",
        "# User will ask question in next turn.\n",
        "workflow.add_edge(\"load_embed\", END) # End the flow after embedding is confirmed <---\n",
        "\n",
        "\n",
        "# Conditional edge after routing the query\n",
        "workflow.add_conditional_edges(\n",
        "    \"route_query\",\n",
        "    lambda x: x['last_node_run'], # This needs correction - routing node returns the *next* node name directly\n",
        "    {\n",
        "        \"retrieve_docs\": \"retrieve_docs\",\n",
        "        \"web_search_agent\": \"web_search_agent\",\n",
        "         # Add a direct path if neither is needed (optional)\n",
        "        # \"generate_response\": \"generate_response\"\n",
        "    }\n",
        ")\n",
        "# *Correction*: The lambda for conditional edges should directly return the next node's name string.\n",
        "# The route_query_node *returns* the name of the next node.\n",
        "workflow.add_conditional_edges(\n",
        "    \"route_query\",\n",
        "    lambda state: route_query_node(state), # Re-run the router logic to get the destination\n",
        "    {\n",
        "        \"retrieve_docs\": \"retrieve_docs\",\n",
        "        \"web_search_agent\": \"web_search_agent\",\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "# After retrieving docs or searching web, generate the response\n",
        "workflow.add_edge(\"retrieve_docs\", \"generate_response\")\n",
        "workflow.add_edge(\"web_search_agent\", \"generate_response\")\n",
        "\n",
        "# After generating response, end the current turn\n",
        "workflow.add_edge(\"generate_response\", END)\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()\n",
        "\n",
        "\n",
        "# --- 5. Run the Chatbot ---\n",
        "print(\"Chatbot initialized. Type a path to a PDF/DOCX file to load, or ask a question.\")\n",
        "print(\"Type 'quit' or 'exit' to end.\")\n",
        "\n",
        "# Keep track of the vector store across interactions\n",
        "current_vectorstore = None\n",
        "current_retriever = None\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() in [\"quit\", \"exit\"]:\n",
        "        break\n",
        "\n",
        "    # Prepare the input for the graph\n",
        "    inputs = {\"messages\": [HumanMessage(content=user_input)]}\n",
        "\n",
        "    # Pass the current vector store/retriever *into* the invocation if they exist\n",
        "    # The graph's state mechanism handles passing it between internal nodes,\n",
        "    # but we need to inject it for the *start* of subsequent turns if needed.\n",
        "    config = {\"configurable\": {}} # Can be used for thread-specific data like thread_id\n",
        "    if current_vectorstore:\n",
        "        # How to pass existing state? LangGraph typically handles this via checkpoints\n",
        "        # or by modifying the initial input for `stream` or `invoke`.\n",
        "        # For this simple loop, let's manually inject into the initial input.\n",
        "        # This isn't the standard LangGraph way for long-term state,\n",
        "        # but works for this script structure.\n",
        "         inputs['vectorstore'] = current_vectorstore\n",
        "         inputs['retriever'] = current_retriever\n",
        "\n",
        "\n",
        "    # Invoke the graph\n",
        "    # Use stream to see intermediate steps (optional)\n",
        "    # for event in app.stream(inputs, config=config):\n",
        "    #     for key, value in event.items():\n",
        "    #         print(f\"--- Node: {key} ---\")\n",
        "    #         # print(value) # Print node output\n",
        "\n",
        "    # Or just invoke for the final result\n",
        "    final_state = app.invoke(inputs, config=config)\n",
        "\n",
        "    # Update the persistent vector store/retriever for the next loop iteration\n",
        "    if final_state.get('vectorstore'):\n",
        "        current_vectorstore = final_state['vectorstore']\n",
        "        current_retriever = final_state['retriever']\n",
        "\n",
        "\n",
        "    # Display the last AI message\n",
        "    if final_state and final_state.get('messages'):\n",
        "      last_ai_message = final_state['messages'][-1]\n",
        "      if isinstance(last_ai_message, AIMessage):\n",
        "          print(f\"AI: {last_ai_message.content}\")\n",
        "      # Handle cases where the last message might not be AI (e.g., error during loading)\n",
        "      elif isinstance(last_ai_message, HumanMessage) and len(final_state['messages']) > 1:\n",
        "          # Look for the second to last if the last is Human (unlikely with this flow)\n",
        "          second_last = final_state['messages'][-2]\n",
        "          if isinstance(second_last, AIMessage):\n",
        "              print(f\"AI: {second_last.content}\")\n",
        "\n",
        "    print(\"-\" * 30) # Separator for clarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "Ok71oo7CZU07",
        "outputId": "d5d99b96-2a6a-4ed3-9f37-24d05f3c0aff"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-28-0b9362fdc7da>, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-28-0b9362fdc7da>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    find using prompt the domain and the complexity for the embedding to be used ->\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "find using prompt the domain and the complexity for the embedding to be used ->\n",
        "pass the output to the other nodes to specified embidding type from the state ->\n",
        "get the doc vetorized andd store that to store ->\n",
        "now embed the original prompt and search it ->\n",
        "fetch the result and put twogether with the prompt to the lllm ->\n",
        "get reuslt\n",
        "\n",
        "\n",
        "and if there is no document in the state give the prompt to the llm ->\n",
        "get result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yb8bS3Azad_b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvYTxKLsbGfV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbX4HAHpbI7G"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "# from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_core.memory import BaseMemory\n",
        "from typing import Dict, List, Optional, Any\n",
        "import numpy\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langgraph.graph import StateGraph, END\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict"
      ],
      "metadata": {
        "id": "R8WroQlhPXjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "StateGraph()"
      ],
      "metadata": {
        "id": "crfDcDXaPuLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Ensure you have your OpenAI API key configured\n",
        "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"  # Replace with your actual API key\n",
        "\n",
        "# --------------------------------------------------\n",
        "# Define the State\n",
        "# --------------------------------------------------\n",
        "\n",
        "def load_pipeline():\n",
        "  pipe = pipeline(\n",
        "      \"text-generation\",\n",
        "      model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
        "      torch_dtype=torch.bfloat16,\n",
        "      device_map=\"auto\",\n",
        "      max_new_tokens=256,\n",
        "  )\n",
        "\n",
        "  # Set custom chat template\n",
        "\"\"\"\n",
        "{% for message in messages %}\n",
        "{% if message['role'] == 'user' %}\n",
        "{{ '<|user|>\n",
        "' + message['content'] + eos_token }}\n",
        "{% elif message['role'] == 'system' %}\n",
        "{{ '<|system|>\n",
        "' + message['content'] + eos_token }}\n",
        "{% elif message['role'] == 'assistant' %}\n",
        "{{ '<|assistant|>\n",
        "'  + message['content'] + eos_token }}\n",
        "{% endif %}\n",
        "{% if loop.last and add_generation_prompt %}\n",
        "{{ '<|assistant|>' }}\n",
        "{% endif %}\n",
        "{% endfor %}\n",
        "\"\"\"\n",
        "\n",
        "  tinyllama_chat_template = (\n",
        "      \"{% for message in messages %}\"\n",
        "      \"{% if message['role'] == 'system' %}\"\n",
        "      \"<|system|>\\n{{ message['content'] }}<|end|>\\n\"\n",
        "      \"{% elif message['role'] == 'user' %}\"\n",
        "      \"<|user|>\\n{{ message['content'] }}<|end|>\\n\"\n",
        "      \"{% elif message['role'] == 'assistant' %}\"\n",
        "      \"<|assistant|>\\n{{ message['content'] }}<|end|>\\n\"\n",
        "      \"{% endif %}\"\n",
        "      \"{% endfor %}\"\n",
        "      \"{% if add_generation_prompt %}\"\n",
        "      \"<|assistant|>\\n\"\n",
        "      \"{% endif %}\"\n",
        "  )\n",
        "  try:\n",
        "      pipe.tokenizer.chat_template = tinyllama_chat_template\n",
        "  except AttributeError:\n",
        "      st.error(\"Failed to set chat template on tokenizer.\")\n",
        "\n",
        "  return pipe\n",
        "\n",
        "pipe = load_pipeline()\n",
        "hf = HuggingFacePipeline(pipeline=pipe)\n",
        "chat_model = ChatHuggingFace(llm=hf)\n",
        "\n",
        "\n",
        "class GraphState(BaseMemory):\n",
        "    \"\"\"State for the agent.\"\"\"\n",
        "\n",
        "    prompt: str\n",
        "    documents: Optional[List[str]] = None\n",
        "    embedding_type: Optional[str] = None\n",
        "    embedding_complexity: Optional[str] = None\n",
        "    vectorstore: Optional[Chroma] = None   # <------- milvus\n",
        "    search_results: Optional[List[str]] = None\n",
        "    llm_output: Optional[str] = None\n",
        "    final_result: Optional[str] = None\n",
        "\n",
        "    @property\n",
        "    def memory_variables(self) -> List[str]:\n",
        "        \"\"\"Return history buffer.\"\"\"\n",
        "        return self.__class__.__dict__.keys()\n",
        "\n",
        "    def load_memory_variables(self, inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Return history buffer.\"\"\"\n",
        "        return {**self.__dict__}\n",
        "\n",
        "    def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, Any]) -> None:\n",
        "        \"\"\"Save context to memory.\"\"\"\n",
        "        if \"prompt\" in inputs:\n",
        "            self.prompt = inputs[\"prompt\"]\n",
        "        if \"documents\" in inputs:\n",
        "            self.documents = inputs[\"documents\"]\n",
        "        if \"embedding_type\" in outputs:\n",
        "            self.embedding_type = outputs[\"embedding_type\"]\n",
        "        if \"embedding_complexity\" in outputs:\n",
        "            self.embedding_complexity = outputs[\"embedding_complexity\"]\n",
        "        if \"vectorstore\" in outputs:\n",
        "            self.vectorstore = outputs[\"vectorstore\"]\n",
        "        if \"search_results\" in outputs:\n",
        "            self.search_results = outputs[\"search_results\"]\n",
        "        if \"llm_output\" in outputs:\n",
        "            self.llm_output = outputs[\"llm_output\"]\n",
        "        if \"final_result\" in outputs:\n",
        "            self.final_result = outputs[\"final_result\"]\n",
        "\n",
        "    def clear(self) -> None:\n",
        "        \"\"\"Clear memory.\"\"\"\n",
        "        self.prompt = \"\"\n",
        "        self.documents = None\n",
        "        self.embedding_type = None\n",
        "        self.embedding_complexity = None\n",
        "        self.vectorstore = None\n",
        "        self.search_results = None\n",
        "        self.llm_output = None\n",
        "        self.final_result = None\n",
        "\n",
        "# --------------------------------------------------\n",
        "# Define Nodes\n",
        "# --------------------------------------------------\n",
        "\n",
        "def find_embedding_needs(state: GraphState):\n",
        "    \"\"\"Find the domain and complexity for the embedding.\"\"\"\n",
        "    prompt_template = PromptTemplate.from_template(\n",
        "        \"Analyze the following prompt to determine the domain and the complexity of the embedding that would be most suitable. \"\n",
        "        \"Consider factors like the specificity of the topic and the level of detail required.\\n\\nPrompt: {prompt}\\n\\n\"\n",
        "        \"Provide your answer in the following format:\\nDomain: [domain]\\nComplexity: [complexity]\"\n",
        "    )\n",
        "    chain = LLMChain(prompt=prompt_template, llm=chat_model, output_key=\"embedding_needs\")\n",
        "    result = chain.invoke({\"prompt\": state.prompt})\n",
        "    # Correction: Parse the output to separate domain and complexity\n",
        "    print(result,end=\"\\n-------------\\n\")\n",
        "    output_str = result[\"embedding_needs\"]\n",
        "    domain_line = next((line for line in output_str.split('\\n') if line.startswith('Domain:')), None)\n",
        "    complexity_line = next((line for line in output_str.split('\\n') if line.startswith('Complexity:')), None)\n",
        "\n",
        "    domain = domain_line.split(': ')[1] if domain_line else None\n",
        "    complexity = complexity_line.split(': ')[1] if complexity_line else None\n",
        "\n",
        "    return {\"embedding_type\": domain, \"embedding_complexity\": complexity}\n",
        "\n",
        "def specify_embedding_type(state: GraphState):\n",
        "    \"\"\"Specify the embedding type based on domain and complexity.\"\"\"\n",
        "    # Correction: Implement logic to choose embedding type based on state\n",
        "    domain = state.embedding_type\n",
        "    complexity = state.embedding_complexity\n",
        "    print(\"1\\n-------------\\n\")\n",
        "\n",
        "    # Example logic (can be more sophisticated)\n",
        "    if domain == \"general\" and complexity == \"low\":\n",
        "        embedding_model = \"OpenAIEmbeddings\"\n",
        "    elif domain == \"technical\" and complexity == \"high\":\n",
        "        embedding_model = \"OpenAIEmbeddings\" # You might choose a different embedding here\n",
        "    else:\n",
        "        embedding_model = \"OpenAIEmbeddings\" # Default\n",
        "\n",
        "    return {\"embedding_model_name\": embedding_model}\n",
        "\n",
        "def vectorize_documents(state: GraphState):\n",
        "    \"\"\"Vectorize documents and store them.\"\"\"\n",
        "    print(\"2\\n-------------\\n\")\n",
        "    if state.documents:\n",
        "        # Correction: Access embedding model name from the state\n",
        "        embedding_model_name = state.embedding_model_name\n",
        "        embeddings = OpenAIEmbeddings() # For simplicity, using OpenAIEmbeddings directly based on the name\n",
        "\n",
        "        # Correction: Ensure documents are strings for embedding\n",
        "        texts = state.documents\n",
        "\n",
        "        # Correction: Use Chroma.from_texts for direct creation\n",
        "        vectorstore = Chroma.from_texts(texts=texts, embedding=embeddings)\n",
        "        return {\"vectorstore\": vectorstore}\n",
        "    else:\n",
        "        return {}\n",
        "\n",
        "def embed_and_search_prompt(state: GraphState):\n",
        "    \"\"\"Embed the original prompt and search the vector store.\"\"\"\n",
        "    print(\"3\\n-------------\\n\")\n",
        "    if state.vectorstore:\n",
        "        embeddings = OpenAIEmbeddings() # Using default embeddings for query\n",
        "        results = state.vectorstore.similarity_search(state.prompt)\n",
        "        return {\"search_results\": results}\n",
        "    else:\n",
        "        return {}\n",
        "\n",
        "def fetch_results_and_pass_to_llm(state: GraphState):\n",
        "    \"\"\"Fetch the result and put together with the prompt to the LLM.\"\"\"\n",
        "    print(\"4\\n-------------\\n\")\n",
        "    llm = chat_model\n",
        "    prompt_template = PromptTemplate.from_template(\n",
        "        \"You are a helpful assistant. Answer the user's question based on the following context:\\n\\nContext: {context}\\n\\nQuestion: {prompt}\\n\\nAnswer:\"\n",
        "    )\n",
        "    context = \"\\n\".join([doc.page_content for doc in state.search_results]) if state.search_results else \"No relevant context found.\"\n",
        "    chain = LLMChain(prompt=prompt_template, llm=llm, output_key=\"llm_output\")\n",
        "    result = chain.invoke({\"prompt\": state.prompt, \"context\": context})\n",
        "    return {\"llm_output\": result[\"llm_output\"]}\n",
        "\n",
        "def give_prompt_to_llm(state: GraphState):\n",
        "    \"\"\"Give the prompt directly to the LLM if no documents are available.\"\"\"\n",
        "    print(\"5\\n-------------\\n\")\n",
        "    llm = chat_model\n",
        "    prompt_template = PromptTemplate.from_template(\"{prompt}\")\n",
        "    chain = LLMChain(prompt=prompt_template, llm=llm, output_key=\"llm_output\")\n",
        "    result = chain.invoke({\"prompt\": state.prompt})\n",
        "    return {\"llm_output\": result[\"llm_output\"]}\n",
        "\n",
        "def final_output(state: GraphState):\n",
        "    \"\"\"Return the final result.\"\"\"\n",
        "    print(\"6\\n-------------\\n\")\n",
        "    return {\"final_result\": state.llm_output}\n",
        "\n",
        "# --------------------------------------------------\n",
        "# Define Edges\n",
        "# --------------------------------------------------\n",
        "\n",
        "def should_vectorize(state: GraphState):\n",
        "    \"\"\"Determine if there are documents to vectorize.\"\"\"\n",
        "    print(\"7\\n-------------\\n\")\n",
        "    return bool(state.documents)\n",
        "\n",
        "# --------------------------------------------------\n",
        "# Build the Graph\n",
        "# --------------------------------------------------\n",
        "builder = StateGraph(GraphState)\n",
        "\n",
        "# Entrypoint\n",
        "builder.add_node(\"find_embedding_needs\", find_embedding_needs)\n",
        "builder.set_entry_point(\"find_embedding_needs\")\n",
        "\n",
        "# Node to specify embedding type\n",
        "builder.add_node(\"specify_embedding_type\", specify_embedding_type)\n",
        "builder.add_edge(\"find_embedding_needs\", \"specify_embedding_type\")\n",
        "\n",
        "# Conditional path for vectorizing documents\n",
        "builder.add_node(\"vectorize_documents\", vectorize_documents)\n",
        "builder.add_conditional_edges(\n",
        "    \"specify_embedding_type\",\n",
        "    should_vectorize,\n",
        "    {True: \"embed_and_search_prompt\", False: \"no_documents\"},\n",
        ")\n",
        "\n",
        "# Node to embed and search the prompt\n",
        "builder.add_node(\"embed_and_search_prompt\", embed_and_search_prompt)\n",
        "builder.add_edge(\"vectorize_documents\", \"embed_and_search_prompt\")\n",
        "\n",
        "# Node to fetch results and pass to LLM\n",
        "builder.add_node(\"fetch_results_and_pass_to_llm\", fetch_results_and_pass_to_llm)\n",
        "builder.add_edge(\"embed_and_search_prompt\", \"fetch_results_and_pass_to_llm\")\n",
        "builder.add_edge(\"fetch_results_and_pass_to_llm\", END)\n",
        "\n",
        "# Node for the case where there are no documents\n",
        "builder.add_node(\"no_documents\", give_prompt_to_llm)\n",
        "builder.add_edge(\"no_documents\", END)\n",
        "\n",
        "# Compile the graph\n",
        "graph = builder.compile()\n",
        "\n",
        "# --------------------------------------------------\n",
        "# Example Usage\n",
        "# --------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Example with documents\n",
        "    inputs_with_docs = {\n",
        "        \"prompt\": \"What are the key features of LangGraph?\",\n",
        "        \"documents\": [\"LangGraph allows you to build conversational agents as state machines.\", \"It provides a way to define nodes and edges for the flow of conversation.\"],\n",
        "    }\n",
        "    result_with_docs = graph.invoke(inputs_with_docs)\n",
        "    print(\"Result with documents:\", result_with_docs)\n",
        "\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Example without documents\n",
        "    inputs_without_docs = {\n",
        "        \"prompt\": \"Tell me a joke.\",\n",
        "    }\n",
        "    result_without_docs = graph.invoke(inputs_without_docs)\n",
        "    print(\"Result without documents:\", result_without_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wq0Gmtbn6izr",
        "outputId": "081a4207-af6c-4b12-c7f8-66321ffd533e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "<ipython-input-4-e811d53ac0f0>:106: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  chain = LLMChain(prompt=prompt_template, llm=chat_model, output_key=\"embedding_needs\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'prompt': 'What are the key features of LangGraph?', 'embedding_needs': '<|user|>\\nAnalyze the following prompt to determine the domain and the complexity of the embedding that would be most suitable. Consider factors like the specificity of the topic and the level of detail required.\\n\\nPrompt: What are the key features of LangGraph?\\n\\nProvide your answer in the following format:\\nDomain: [domain]\\nComplexity: [complexity]</s>\\n<|assistant|>\\nDomain: Natural Language Processing (NLP)\\nComplexity: Medium\\n\\nNLP is a domain that involves the analysis, interpretation, and manipulation of human language. The key features of LangGraph are:\\n\\n1. NLP-specific features: LangGraph is designed to handle NLP-specific features such as tokenization, part-of-speech tagging, and dependency parsing.\\n\\n2. Domain-specific features: LangGraph is designed to handle specific NLP tasks such as sentiment analysis, named entity recognition, and machine translation.\\n\\n3. High-level abstraction: LangGraph is designed to provide a high-level abstraction of NLP tasks, making it easier to integrate with other NLP tools and frameworks.\\n\\n4. Flexibility: LangGraph is designed to be flexible and adaptable to different NLP use cases, making it suitable for a wide range of applications.\\n\\n5. Scalability: LangGraph is designed to be scalable and can handle large datasets, making it suitable for large-scale NLP projects.\\n\\nOverall, LangGraph is a versatile and powerful tool for handling NLP tasks, making it a suitable choice for a wide range of N'}\n",
            "-------------\n",
            "1\n",
            "-------------\n",
            "\n",
            "7\n",
            "-------------\n",
            "\n",
            "3\n",
            "-------------\n",
            "\n",
            "4\n",
            "-------------\n",
            "\n",
            "Result with documents: {'prompt': 'What are the key features of LangGraph?', 'documents': ['LangGraph allows you to build conversational agents as state machines.', 'It provides a way to define nodes and edges for the flow of conversation.'], 'embedding_type': '[domain]', 'embedding_complexity': '[complexity]</s>', 'llm_output': \"<|user|>\\nYou are a helpful assistant. Answer the user's question based on the following context:\\n\\nContext: No relevant context found.\\n\\nQuestion: What are the key features of LangGraph?\\n\\nAnswer:</s>\\n<|assistant|>\\nThe key features of LangGraph are its ability to generate a graph representation of a language, including its vocabulary, grammar, and syntax. It can also analyze the structure and relationships between words, phrases, and sentences in a language. LangGraph is a powerful tool for linguists, language learners, and language teachers who want to understand the structure and function of a language.\"}\n",
            "----------------------------------------\n",
            "{'prompt': 'Tell me a joke.', 'embedding_needs': \"<|user|>\\nAnalyze the following prompt to determine the domain and the complexity of the embedding that would be most suitable. Consider factors like the specificity of the topic and the level of detail required.\\n\\nPrompt: Tell me a joke.\\n\\nProvide your answer in the following format:\\nDomain: [domain]\\nComplexity: [complexity]</s>\\n<|assistant|>\\nPrompt: Write a 500-word short story in third-person omniscient point of view about a character who discovers a hidden talent for playing the piano. The story should include vivid descriptions of the character's emotional journey as they overcome their fear of playing the piano and develop their skills. The story should also explore themes of self-discovery, perseverance, and the power of music to connect people. The character's piano playing should be described in detail, including the style and tone of the music they play. The story should have a clear beginning, middle, and end, and should be written in a style that engages the reader and leaves a lasting impression.\"}\n",
            "-------------\n",
            "1\n",
            "-------------\n",
            "\n",
            "7\n",
            "-------------\n",
            "\n",
            "5\n",
            "-------------\n",
            "\n",
            "Result without documents: {'prompt': 'Tell me a joke.', 'embedding_type': '[domain]', 'embedding_complexity': '[complexity]</s>', 'llm_output': \"<|user|>\\nTell me a joke.</s>\\n<|assistant|>\\nSure, here's a joke for you:\\n\\nQ: What do you get when you cross a pig with a pencil?\\nA: A pig with a pencil.\\n\\nThis joke is a classic example of a punchline, which is a comedic statement that ends a joke. The punchline is usually a humorous or ridiculous statement that makes the audience laugh. In this joke, the pig and the pencil are the main characters, and the punchline is the absurdity of their union. The pig with a pencil is a ridiculous and humorous image that makes the audience laugh.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory = MemorySaver()\n",
        "\n",
        "# Finally, we compile it!\n",
        "# This compiles it into a LangChain Runnable,\n",
        "# meaning you can use it as you would any other runnable\n",
        "\n",
        "# We add in `interrupt_before=[\"action\"]`\n",
        "# This will add a breakpoint before the `action` node is called\n",
        "app = workflow.compile(checkpointer=memory)\n",
        "\n",
        "all_states = []\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "for state in app.get_state_history(config):\n",
        "    print(state)\n",
        "    all_states.append(state)\n",
        "    print(\"--\")"
      ],
      "metadata": {
        "id": "VfqkXPUBX4If"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_without_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nl_Sn9PTWiNP",
        "outputId": "00eac125-f21d-4ce4-a09b-d4004aa72c94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'prompt': 'Tell me a joke.',\n",
              " 'embedding_type': '[domain]',\n",
              " 'embedding_complexity': '[complexity]</s>',\n",
              " 'llm_output': \"<|user|>\\nTell me a joke.</s>\\n<|assistant|>\\nSure, here's a joke for you:\\n\\nQ: What do you get when you cross a pig with a pencil?\\nA: A pig with a pencil.\\n\\nThis joke is a classic example of a punchline, which is a comedic statement that ends a joke. The punchline is usually a humorous or ridiculous statement that makes the audience laugh. In this joke, the pig and the pencil are the main characters, and the punchline is the absurdity of their union. The pig with a pencil is a ridiculous and humorous image that makes the audience laugh.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EEWkzTnlKPbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### the milvus"
      ],
      "metadata": {
        "id": "2PgsCx0gKZa7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9xUq7jKmfTJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b23761d-b662-4a78-c06f-9978f29c42a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/227.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m225.3/227.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.0 requires grpcio>=1.71.0, but you have grpcio 1.67.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -Uq pymilvus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6SPx9nUBhmO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ace55606-a3f8-42eb-87ff-f278580e5e27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q pymilvus[model]\n",
        "# or pip install \"pymilvus[model]\" for zsh."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3i_Qen2kYwz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333,
          "referenced_widgets": [
            "b0dbd91b4b66457f97d0873d73bd83da",
            "e17ddbbea1014ab9898b60405db11abd",
            "542436179cca4a5699ccb1d05818cf98",
            "3ab6138432dd4021806ac8464879fdff",
            "d777bc0c95584e8e8ac4e488d455afc7",
            "5fa7423fb608479582bd79a3d34117b1",
            "a8e5012eb251486b9a7eff70dc2a7368",
            "0ed23936b7ab4f748e4e3bba3ef37b62",
            "a498a58571374fc9b28a2be66a8a5b02",
            "dc3f866575a045649befa64b29c4cf26",
            "0f4dc53ac3a04616b3c70c3b63b0b691",
            "770a89bb35b54dc49c7e8c7e73fb3cc6",
            "25425ba4f50f479fa1889554fa0e3a80",
            "cacfbc0407364cd98723d0aa551f566c",
            "e53d90e5121e461f9e9a3d723d1ef75a",
            "58da9256a7a545d79ab0ba81074e2cd3",
            "a0cca9fdffae403f9239391b87050ea9",
            "46ba0ae73a2b487bb288847e776d4cbe",
            "f06cfe6b4bdc458fb97731faf93209dc",
            "6d22bb65f73a4e119a04bd1c7d51e149",
            "b5cd29ea3e0e4a0e9f3459391f053df9",
            "28f44feff17647c6869302fe18b6aedc",
            "fa79f234757e4f7abdb951f52a44e318",
            "1b567fe0acce45e89735402beb24aa38",
            "cba74810a01c4f23af340ce575ff90f9",
            "d601b0e6158543be856eb435f8b50f74",
            "209f0e836a594c30abedc451c0262000",
            "eff5a5c9a73845e4a0a9f2abe19d35de",
            "74da144c12a24216b54dff8e885b7343",
            "53c5b93eef9b4f1eb9ba6591ac082f52",
            "2e37ab95168f4e189093b6a9c2a792a2",
            "95ccc27890704a528ef6a0d84e9bf755",
            "e8ec1594354f47c696aa5fdc64ce49e1",
            "90ad0dd329234b718113b02c2d0038b2",
            "4fa40c73ae6548598427f19ac176586e",
            "97ff00e97a2847e7879d34dfe214bf41",
            "829dfb0d417441b491a4a8d25d399197",
            "79e0f3da7b324ecda659fe912b712432",
            "34112cf4b6dc4c228faa779576046a39",
            "0e6c821400ba4c348b689264d8663645",
            "daa6b14db6184827b5861734791f338e",
            "5b3adcec973142be90b634118b24a58f",
            "ae721a4a167240b1bbdf157893d2cb5b",
            "d0bc52dde2f64e40a30db5833d825d1e",
            "55c517b38d134ccc9b8ac1cbd52baa57",
            "be5ead46a2a34c98a545df8899832692",
            "a80f87e57229423aaccec53629d1b33c",
            "dfd50c6966e14e36afdb4a1767c87934",
            "324ea00ffe844f5da191474e4bcb3048",
            "12def2f7d2ce4e3684f3eb84b988580e",
            "35b0fa27a2794c15b3c19edc9a3ee075",
            "f969462f8f6646c695782147c4233e4b",
            "5ee50c5b76604b1ba77206294cc294f3",
            "a676ecf11fae494ca586ac8c5e5b015e",
            "444a50f6507c40739ec9cc496b5a44fc",
            "b25b9f5d0087456abf9b0055954ec4a8",
            "dfb548c126ca4362a15962098693baa2",
            "b4ec4f40edfe416eb9a9f6b521fc8f56",
            "8e92318390d84338a0cfe6ebfb5cd4f2",
            "f49e63651940457280fa268915749ac3",
            "436e66cb9594424abde9c348c412061f",
            "2e43760a1aee42149e7e1d5c9adbc63b",
            "dd223c5c95224226ba65f83639e71f39",
            "da5d92f5d9b84ad79dbdc56e12e2a75d",
            "4bca69c76b5e44c5b8e292b6115c72ff",
            "5e0e85e8a7ff4e39acdd48935f8bbfe7"
          ]
        },
        "outputId": "a3813c82-a768-40c3-fb30-d6dde37b23ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/465 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0dbd91b4b66457f97d0873d73bd83da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/827 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "770a89bb35b54dc49c7e8c7e73fb3cc6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa79f234757e4f7abdb951f52a44e318"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90ad0dd329234b718113b02c2d0038b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/245 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55c517b38d134ccc9b8ac1cbd52baa57"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.onnx:   0%|          | 0.00/46.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b25b9f5d0087456abf9b0055954ec4a8"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from pymilvus import model\n",
        "embedding_fn = model.DefaultEmbeddingFunction()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3XMpwBvkYw2"
      },
      "outputs": [],
      "source": [
        "vectors1 = embedding_fn.encode_queries([\"Project Documentation: AI-Powered CV Parsing Microservice with Caching and AWS Translate  Objective: Develop an AI-powered CV parsing microservice that extracts data from user-uploaded CVs, maps the data to a predefined CandidateProfile schema, and stores it in MongoDB. The microservice must support multiple languages, cache parsed results for efficiency, provide error handling, and allow users to view their parsed CVs in both English and their preferred language.  Microservice Workflow Overview: 1. User Account Creation: Users create an account and select their preferred language. Before uploading a CV, users complete a series of tests and assessments to build their profile. 2. CV Upload and Parsing: Users upload their CVs in various formats (PDF, Word, Google Docs, etc.). The microservice parses the CV using AI/NLP services to extract key data such as personal information, experience, education, skills, and competencies.\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55028a41-f3b5-4c2c-9382-47a02b43e935",
        "id": "8uPb25BDkYw4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "len(vectors1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3Y1qi1jBddS",
        "outputId": "a90cb872-6989-495e-c074-c99d2b98de0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "WARNING:transformers_modules.nomic-ai.nomic-bert-2048.e5042dce39060cc34bc223455f25cf1d26db4655.modeling_hf_nomic_bert:!!!!!!!!!!!!megablocks not available, using torch.matmul instead\n",
            "WARNING:transformers_modules.nomic-ai.nomic-bert-2048.e5042dce39060cc34bc223455f25cf1d26db4655.modeling_hf_nomic_bert:<All keys matched successfully>\n"
          ]
        }
      ],
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "model_name = \"nomic-ai/nomic-embed-text-v1\"\n",
        "model_kwargs = {'device': 'cpu','trust_remote_code':True,}\n",
        "encode_kwargs = {'normalize_embeddings': False,'dim':768}\n",
        "hf = HuggingFaceEmbeddings(\n",
        "    model_name=model_name,\n",
        "    model_kwargs=model_kwargs,\n",
        "    encode_kwargs=encode_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFTOXIm4KDTK",
        "outputId": "e7ec11eb-dfa9-409e-e1a9-ed3c43d8d1f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(hf.embed_query(\"hello world\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-kRwuyVbfCs",
        "outputId": "e117bd13-6cd9-40a4-9009-059801024b3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "from pymilvus import utility\n",
        "client.list_collections()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGvSWqEgVwzC"
      },
      "outputs": [],
      "source": [
        "client.drop_collection(\"rag_documents_nomic2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7V3gvcV-meZy",
        "outputId": "8fdbe658-cf44-4e30-b243-c805378250d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collection 'rag_documents_nomic2' already exists.\n",
            "Index created on 'embedding' field.\n",
            "(768,)\n",
            "(768,)\n",
            "Successfully inserted 2 documents.\n",
            "\n",
            "Content for user 'kartik moyade':\n",
            "- {'id': 2, 'distance': 1.2578697204589844, 'entity': {'content_string': 'Technological Stack: \\uf0a7 Backend Framework: Node.js (Express.js) \\uf0a7 Database: MongoDB (for storing candidate profile data) \\uf0a7 Caching: Centralized cache manager (cacheManager.js) \\uf0a7 NLP/AI: Third-party parsing services (e.g., Affinda) or custom NLP models \\uf0a7 Translation: AWS Translate (via translateUtils.js) \\uf0a7 Authentication & Security: Centralized and managed by TRIPA (e.g., JWT-based authentication, OAuth) \\uf0a7 Error Handling: handleError and logger utilities for centralized logging and error management \\uf0a7 Monitoring & Health Checks: Integrate monitoring tools and health check endpoints for real-time monitoring.  Additional Requirements for Robustness: 1. Failover and Resilience: \\uf0a7 In case of AI/NLP or translation service failure, fallback mechanisms must gracefully handle errors (e.g., log failures, notify users, and use default values where appropriate). ', 'page_number': 2, 'source': 'TRIPA CV Parsing Project.pdf', 'user': 'kartik moyade'}}\n"
          ]
        }
      ],
      "source": [
        "from pymilvus import MilvusClient, FieldSchema, DataType, CollectionSchema, IndexType\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Milvus Lite doesn't require a server, it runs locally\n",
        "client = MilvusClient(\"milvus_demo.db\")\n",
        "# Define collection name and embedding dimension for nomic-ai/nomic-embed-text-v1\n",
        "COLLECTION_NAME = \"rag_documents_nomic2\"\n",
        "EMBEDDING_DIMENSION = 768\n",
        "\n",
        "# Load the nomic embedding model from Hugging Face\n",
        "# embedding_model = hf\n",
        "\n",
        "# Define the schema for the collection\n",
        "fields = [\n",
        "    FieldSchema(name=\"page_number\", dtype=DataType.INT64, is_primary=True, auto_id=False),\n",
        "    FieldSchema(name=\"source\", dtype=DataType.VARCHAR, max_length=256),\n",
        "    FieldSchema(name=\"user\", dtype=DataType.VARCHAR, max_length=256),\n",
        "    FieldSchema(name=\"content_string\", dtype=DataType.VARCHAR, max_length=4096),\n",
        "    FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=EMBEDDING_DIMENSION)\n",
        "]\n",
        "\n",
        "schema = CollectionSchema(fields=fields, description=\"Collection for RAG documents with Nomic embeddings\")\n",
        "\n",
        "# Create the collection\n",
        "if 'rag_documents_nomic2' in client.list_collections():\n",
        "  client.load_collection(collection_name=COLLECTION_NAME)\n",
        "  print(f\"Collection '{COLLECTION_NAME}' already exists.\")\n",
        "else:\n",
        "  client.create_collection(collection_name=COLLECTION_NAME, schema=schema,dimension=EMBEDDING_DIMENSION)\n",
        "  print(f\"Collection '{COLLECTION_NAME}' created successfully.\")\n",
        "\n",
        "# Define the index for the embedding field\n",
        "index_params= client.prepare_index_params()\n",
        "\n",
        "index_params.add_index(\n",
        "    field_name=\"embedding\", # Name of the vector field to be indexed\n",
        "    index_type=\"FLAT\", # Type of the index to create\n",
        "    index_name=\"vector_index\", # Name of the index to create\n",
        "    metric_type=\"L2\", # Metric type used to measure similarity\n",
        "    # params={\"nlist\": 128} # No additional parameters required for FLAT\n",
        "    params={} # No additional parameters required for FLAT\n",
        ")\n",
        "\n",
        "\n",
        "try:\n",
        "    index_info = client.describe_index(collection_name=COLLECTION_NAME,index_name=\"embedding\")\n",
        "    if not index_info:\n",
        "        client.create_index(collection_name=COLLECTION_NAME, index_params=index_params)\n",
        "        print(\"Index created on 'embedding' field.\")\n",
        "    else:\n",
        "        print(\"Index already exists on 'embedding' field.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating or checking index: {e}\")\n",
        "\n",
        "def insert_documents(collection, documents):\n",
        "    \"\"\"Inserts multiple Langchain Document objects into the Milvus Lite collection using Nomic embeddings.\n",
        "\n",
        "    Args:\n",
        "        collection: The Milvus Lite collection object.\n",
        "        documents: A list of Langchain Document objects.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    for doc in documents:\n",
        "        try:\n",
        "            page_number = int(doc.metadata.get('page'))\n",
        "            source = doc.metadata.get('source')\n",
        "            user = doc.metadata.get('user')\n",
        "            content_string = doc.page_content\n",
        "\n",
        "            if page_number is None or source is None or user is None or content_string is None:\n",
        "                print(f\"Skipping document due to missing metadata or content: {doc}\")\n",
        "                continue\n",
        "\n",
        "            # embedding = np.array(embedding_model.embed_query(content_string))\n",
        "            embedding = embedding_fn.encode_queries([content_string]) # <------------\n",
        "            print(embedding[0].shape) # <------------\n",
        "            data.append({\n",
        "                \"page_number\": page_number,\n",
        "                \"source\": source,\n",
        "                \"user\": user,\n",
        "                \"content_string\": content_string,\n",
        "                \"embedding\": embedding[0] # <-----\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing document: {doc}. Error: {e}\")\n",
        "            continue\n",
        "\n",
        "    if data:\n",
        "        try:\n",
        "            collection.insert(collection_name=COLLECTION_NAME,data=data)\n",
        "            print(f\"Successfully inserted {len(data)} documents.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error inserting documents into Milvus: {e}\")\n",
        "    else:\n",
        "        print(\"No valid documents to insert.\")\n",
        "\n",
        "def get_content_by_user(collection, user_name):\n",
        "    \"\"\"Retrieves the content strings for documents belonging to a specific user.\n",
        "\n",
        "    Args:\n",
        "        collection: The Milvus Lite collection object.\n",
        "        user_name: The name of the user to filter by.\n",
        "\n",
        "    Returns:\n",
        "        A list of content strings.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # data=embedding_fn.embed_query(\"data base used in the project is mongodb and rds form aws.\")\n",
        "        data=embedding_fn.encode_queries([\"error handling ai/nlp authentication & security\"]) # <------------\n",
        "        # data=np.array(data)\n",
        "        # print(data.shape)\n",
        "\n",
        "        results = client.search(\n",
        "            collection_name=COLLECTION_NAME,\n",
        "            data=data,\n",
        "            filter=f' user == \"{user_name}\" ',\n",
        "            limit=2,\n",
        "            output_fields=[\"page_number\",\"source\", \"content_string\",\"user\"]\n",
        "        )\n",
        "        content_list = []\n",
        "        for topk_res in results:\n",
        "          for one_res in topk_res:\n",
        "            content_list.append(one_res)\n",
        "        return content_list\n",
        "    except Exception as e:\n",
        "        print(f\"Error querying documents by user: {e}\")\n",
        "        return []\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example documents in Langchain Document format\n",
        "    from langchain_core.documents import Document\n",
        "\n",
        "    documents_to_insert = [\n",
        "        Document(metadata={'page': '1', 'source': 'TRIPA CV Parsing Project.pdf', 'user': 'kartik moyade'}, page_content='Project Documentation: AI-Powered CV Parsing Microservice with Caching and AWS Translate  Objective: Develop an AI-powered CV parsing microservice that extracts data from user-uploaded CVs, maps the data to a predefined CandidateProfile schema, and stores it in MongoDB. The microservice must support multiple languages, cache parsed results for efficiency, provide error handling, and allow users to view their parsed CVs in both English and their preferred language.  Microservice Workflow Overview: 1. User Account Creation: Users create an account and select their preferred language. Before uploading a CV, users complete a series of tests and assessments to build their profile. 2. CV Upload and Parsing: Users upload their CVs in various formats (PDF, Word, Google Docs, etc.). The microservice parses the CV using AI/NLP services to extract key data such as personal information, experience, education, skills, and competencies.'),\n",
        "        Document(metadata={'page': '2', 'source': 'TRIPA CV Parsing Project.pdf', 'user': 'kartik moyade'}, page_content='Technological Stack: \\uf0a7 Backend Framework: Node.js (Express.js) \\uf0a7 Database: MongoDB (for storing candidate profile data) \\uf0a7 Caching: Centralized cache manager (cacheManager.js) \\uf0a7 NLP/AI: Third-party parsing services (e.g., Affinda) or custom NLP models \\uf0a7 Translation: AWS Translate (via translateUtils.js) \\uf0a7 Authentication & Security: Centralized and managed by TRIPA (e.g., JWT-based authentication, OAuth) \\uf0a7 Error Handling: handleError and logger utilities for centralized logging and error management \\uf0a7 Monitoring & Health Checks: Integrate monitoring tools and health check endpoints for real-time monitoring.  Additional Requirements for Robustness: 1. Failover and Resilience: \\uf0a7 In case of AI/NLP or translation service failure, fallback mechanisms must gracefully handle errors (e.g., log failures, notify users, and use default values where appropriate). '),\n",
        "    ]\n",
        "\n",
        "    # Insert the example documents\n",
        "    insert_documents(client, documents_to_insert)\n",
        "    # Retrieve content for user \"kartik moyade\"\n",
        "    user_name = \"kartik moyade\"\n",
        "    user_content = get_content_by_user(client, user_name)\n",
        "    print(f\"\\nContent for user '{user_name}':\")\n",
        "    for content in user_content:\n",
        "        print(f\"- {content}\")\n",
        "\n",
        "    # Clean up (optional - uncomment to delete the collection)\n",
        "    # client.drop_collection(COLLECTION_NAME)\n",
        "    # print(f\"Collection '{COLLECTION_NAME}' dropped.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import Dict, Any, List\n",
        "from pymilvus import MilvusClient, CollectionSchema, FieldSchema, DataType\n",
        "from langchain_core.documents import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter # Importing necessary text splitters\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Initialize mock embedding function if not provided\n",
        "try:\n",
        "    embedding_fn # Check if embedding_fn is already defined\n",
        "except NameError:\n",
        "    print(\"embedding_fn not found, using MockEmbeddingFunction.\")\n",
        "    # embedding_fn = MockEmbeddingFunction()\n",
        "\n",
        "\n",
        "# Milvus Client Initialization (from your code)\n",
        "# Ensure Milvus Lite database file path is correctly set\n",
        "MILVUS_DB_PATH = \"milvus_demo.db\"\n",
        "client = MilvusClient(MILVUS_DB_PATH)\n",
        "\n",
        "# Define collection name and embedding dimension (from your code)\n",
        "COLLECTION_NAME = \"rag_documents_nomic2\" # Using the same collection name\n",
        "EMBEDDING_DIMENSION = 768 # Nomic embedding dimension\n",
        "\n",
        "\n",
        "# metadata={\"section\":l,'page': i.metadata[\"page_label\"], \"source\": i.metadata[\"source\"], \"user\": \"your_user\"}))\n",
        "# Define the schema for the collection (from your code)\n",
        "fields = [\n",
        "    FieldSchema(name=\"chunk_id\", dtype=DataType.INT64, is_primary=True, auto_id=True), # Using auto_id for chunks\n",
        "    FieldSchema(name=\"page_section\", dtype=DataType.INT64), # Using auto_id for chunks\n",
        "    FieldSchema(name=\"original_page_number\", dtype=DataType.INT64), # Store original page number\n",
        "    FieldSchema(name=\"source\", dtype=DataType.VARCHAR, max_length=256),\n",
        "    FieldSchema(name=\"user\", dtype=DataType.VARCHAR, max_length=256),\n",
        "    FieldSchema(name=\"content_string\", dtype=DataType.VARCHAR, max_length=4096), # Chunk content\n",
        "    FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=EMBEDDING_DIMENSION)\n",
        "]\n",
        "schema = CollectionSchema(fields=fields, description=\"Collection for RAG documents with Nomic embeddings\")\n",
        "\n",
        "# Create the collection (from your code)\n",
        "if COLLECTION_NAME in client.list_collections():\n",
        "    # client.load_collection(collection_name=COLLECTION_NAME) # Load if exists\n",
        "    print(f\"Collection '{COLLECTION_NAME}' already exists.\")\n",
        "else:\n",
        "    client.create_collection(collection_name=COLLECTION_NAME, schema=schema) # Dimension is in schema\n",
        "    print(f\"Collection '{COLLECTION_NAME}' created successfully.\")\n",
        "\n",
        "# Define the index for the embedding field (from your code)\n",
        "index_params = client.prepare_index_params()\n",
        "index_params.add_index(\n",
        "    field_name=\"embedding\",\n",
        "    index_type=\"FLAT\",\n",
        "    index_name=\"vector_index\",\n",
        "    metric_type=\"L2\",\n",
        "    params={}\n",
        ")\n",
        "\n",
        "# Create or check index (from your code)\n",
        "try:\n",
        "    # describe_index might raise an error if the index doesn't exist,\n",
        "    # so wrap in try-except or check if collection is empty first.\n",
        "    # A simpler approach is to just try creating and catch the exception if it exists.\n",
        "    client.create_index(collection_name=COLLECTION_NAME, index_params=index_params)\n",
        "    print(\"Index created on 'embedding' field (or already exists).\")\n",
        "except Exception as e:\n",
        "    # MilvusClient.create_index is idempotent in recent versions,\n",
        "    # but checking is safer or handle the specific exception if it fails because index exists.\n",
        "    print(f\"Could not create index (it may already exist): {e}\")\n",
        "\n",
        "\n",
        "def insert_chunks_to_milvus(client: MilvusClient, collection_name: str, chunks: List[Document], embedding_fn) -> None:\n",
        "    \"\"\"\n",
        "    Inserts a list of Langchain Document chunks into the Milvus collection.\n",
        "\n",
        "    Args:\n",
        "        client: The MilvusClient instance.\n",
        "        collection_name: The name of the Milvus collection.\n",
        "        chunks: A list of Langchain Document objects (the chunks).\n",
        "        embedding_fn: The function to generate embeddings.\n",
        "    \"\"\"\n",
        "    data_to_insert = []\n",
        "    chunk_contents = [chunk.page_content for chunk in chunks]\n",
        "\n",
        "    if not chunk_contents:\n",
        "        print(\"No chunks to embed and insert.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Generate embeddings for all chunks in a batch\n",
        "        embeddings = embedding_fn.encode_queries(chunk_contents)\n",
        "        print(f\"Generated embeddings for {len(embeddings)} chunks.\")\n",
        "\n",
        "        if len(embeddings) != len(chunks):\n",
        "             print(f\"Warning: Number of embeddings ({len(embeddings)}) does not match number of chunks ({len(chunks)}). Skipping insertion.\")\n",
        "             return\n",
        "\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            # Extract metadata, providing defaults or handling missing keys\n",
        "            page_number = int(chunk.metadata.get('page', -1)) # Use -1 or other indicator if page missing\n",
        "            section = int(chunk.metadata.get('section', -1))\n",
        "            source = chunk.metadata.get('source', 'unknown')\n",
        "            user = chunk.metadata.get('user', 'unknown')\n",
        "            content_string = chunk.page_content\n",
        "\n",
        "            # Basic validation\n",
        "            if not content_string:\n",
        "                print(f\"Skipping chunk {i} due to empty content.\")\n",
        "                continue\n",
        "\n",
        "            # Prepare data for Milvus insertion\n",
        "            data_to_insert.append({\n",
        "                \"original_page_number\": page_number,\n",
        "                \"page_section\":section,\n",
        "                \"source\": source,\n",
        "                \"user\": user,\n",
        "                \"content_string\": content_string,\n",
        "                \"embedding\": embeddings[i]\n",
        "            })\n",
        "\n",
        "        if data_to_insert:\n",
        "            # Insert data into Milvus\n",
        "            insert_result = client.insert(collection_name=collection_name, data=data_to_insert)\n",
        "            print(f\"Successfully inserted {len(data_to_insert)} chunks into '{collection_name}'.\")\n",
        "            # print(f\"Insert result: {insert_result}\") # Optional: print result details\n",
        "        else:\n",
        "            print(\"No valid data prepared for insertion.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during embedding or insertion: {e}\")\n",
        "\n",
        "\n",
        "# def process_legal_medical_records(client: MilvusClient, documents: List[Document], embedding_fn, collection_name: str = COLLECTION_NAME) -> None:\n",
        "def process_legal_medical_records(client: MilvusClient, documents: str, embedding_fn, collection_name: str = COLLECTION_NAME) -> None:\n",
        "    \"\"\"\n",
        "    Processes legal/medical record documents using Hierarchical/Semantic chunking\n",
        "    and inserts the chunks into Milvus.\n",
        "\n",
        "    Args:\n",
        "        client: The MilvusClient instance.\n",
        "        documents: A list of Langchain Document objects (representing full documents).\n",
        "        embedding_fn: The function to generate embeddings.\n",
        "        collection_name: The name of the Milvus collection.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Processing Legal/Medical Records ---\")\n",
        "\n",
        "    # Strategy: Hierarchical/Semantic-Based Chunking\n",
        "    # Using RecursiveCharacterTextSplitter with separators that respect document structure\n",
        "    # and potentially semantic breaks.\n",
        "    # Common separators for structured documents: [\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        "    # Adjust chunk_size and chunk_overlap based on typical document structure and desired chunk granularity\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1000, # Example size, adjust based on typical clause/paragraph length\n",
        "        chunk_overlap=200, # Example overlap to maintain context\n",
        "        separators=[\"\\n\\n\", \"\\n\", \". \", \"! \", \"? \", \" \"] # Prioritize splitting by paragraphs, then sentences, then words\n",
        "    )\n",
        "\n",
        "    docs=[]\n",
        "    for i in PyPDFLoader(uploaded_file).lazy_load():\n",
        "      l=0\n",
        "      for j in text_splitter.create_documents([i.page_content]):\n",
        "        docs.append(Document(page_content=j.page_content, metadata={\"section\":l,'page': i.metadata[\"page_label\"], \"source\": i.metadata[\"source\"], \"user\": \"your_user\"}))\n",
        "        l+=1\n",
        "\n",
        "\n",
        "\n",
        "    # all_chunks = []\n",
        "    # for doc in documents:\n",
        "    #     print(f\"Chunking document: {doc.metadata.get('source', 'unknown')}\")\n",
        "    #     chunks = text_splitter.split_documents([doc])\n",
        "    #     all_chunks.extend(chunks)\n",
        "    #     print(f\"Created {len(chunks)} chunks for this document.\")\n",
        "\n",
        "    print(f\"Total chunks created for legal/medical records: {len(docs)}\")\n",
        "\n",
        "    # Insert the created chunks into Milvus\n",
        "    insert_chunks_to_milvus(client, collection_name, docs, embedding_fn)\n",
        "    print(\"--- Finished Processing Legal/Medical Records ---\")\n",
        "\n",
        "\n",
        "# def process_faq_documents(client: MilvusClient, documents: List[Document], embedding_fn, collection_name: str = COLLECTION_NAME) -> None:\n",
        "def process_faq_documents(client: MilvusClient, documents: str, embedding_fn, collection_name: str = COLLECTION_NAME,user:str=None) -> None:\n",
        "    \"\"\"\n",
        "    Processes FAQ documents using Sentence-Based chunking\n",
        "    and inserts the chunks into Milvus.\n",
        "\n",
        "    Args:\n",
        "        client: The MilvusClient instance.\n",
        "        documents: A list of Langchain Document objects (representing full documents).\n",
        "        embedding_fn: The function to generate embeddings.\n",
        "        collection_name: The name of the Milvus collection.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Processing FAQ Documents ---\")\n",
        "\n",
        "    # Strategy: Sentence-Based Chunking\n",
        "    # Using SentenceSplitter which is good for short, self-contained text like FAQs.\n",
        "    # RecursiveCharacterTextSplitter can also be configured for sentence splitting\n",
        "    # by prioritizing sentence-ending punctuation in separators. Let's use that for consistency\n",
        "    # and control over chunk size if a sentence is very long.\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=200, # Keep chunks relatively small for FAQ\n",
        "        chunk_overlap=50, # Small overlap\n",
        "        separators=[\". \", \"! \", \"? \", \"\\n\", \" \"] # Prioritize splitting by sentence endings\n",
        "    )\n",
        "\n",
        "    docs=[]\n",
        "    for i in PyPDFLoader(documents).lazy_load():\n",
        "      l=0\n",
        "      for j in text_splitter.create_documents([i.page_content]):\n",
        "        docs.append(Document(page_content=j.page_content, metadata={\"section\":l,'page': i.metadata[\"page_label\"], \"source\": i.metadata[\"source\"], \"user\": f\"{user}\"}))\n",
        "        l+=1\n",
        "\n",
        "\n",
        "    # all_chunks = []\n",
        "    # for doc in documents:\n",
        "    #     print(f\"Chunking document: {doc.metadata.get('source', 'unknown')}\")\n",
        "    #     chunks = text_splitter.split_documents([doc])\n",
        "    #     all_chunks.extend(chunks)\n",
        "    #     print(f\"Created {len(chunks)} chunks for this document.\")\n",
        "\n",
        "    print(f\"Total chunks created for FAQ documents: {len(docs)}\")\n",
        "\n",
        "    # Insert the created chunks into Milvus\n",
        "    insert_chunks_to_milvus(client, collection_name, docs, embedding_fn)\n",
        "    print(\"--- Finished Processing FAQ Documents ---\")\n",
        "\n",
        "\n",
        "# Provided get_content_by_user function (slightly adapted for new schema)\n",
        "def get_content_by_user(client: MilvusClient, user_name: str, collection_name: str = COLLECTION_NAME) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Retrieves the content strings for documents belonging to a specific user.\"\"\"\n",
        "    try:\n",
        "        # Embed a query relevant to the content you want to retrieve\n",
        "        # This query should reflect what you'd search for in the vector space\n",
        "        query_embedding = embedding_fn.encode_queries([\"information related to user documents\"])[0] # Example query <-----query\n",
        "\n",
        "        results = client.search(\n",
        "            collection_name=collection_name,\n",
        "            data=[query_embedding], # Search expects a list of vectors\n",
        "            filter=f'user == \"{user_name}\"',\n",
        "            limit=5, # Retrieve top 5 relevant chunks\n",
        "            output_fields=[\"original_page_number\", \"source\", \"content_string\", \"user\"] # Include relevant fields\n",
        "        )\n",
        "\n",
        "        content_list = []\n",
        "        # The structure of results is a list of result sets (one per query vector, here just one)\n",
        "        # Each result set is a list of hits\n",
        "        for topk_res in results:\n",
        "            for one_res in topk_res:\n",
        "                content_list.append(one_res) # Append the hit dictionary\n",
        "\n",
        "        return content_list\n",
        "    except Exception as e:\n",
        "        print(f\"Error querying documents by user: {e}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "# Main execution block\n",
        "if __name__ == \"__main__\":\n",
        "    # Example Legal/Medical Documents\n",
        "    # legal_medical_docs = [\n",
        "    #     Document(metadata={'page': '1', 'source': 'Medical_Report_PatientA.pdf', 'user': 'Dr. Smith'}, page_content='Patient Name: John Doe\\nDate of Birth: 1985-07-20\\nMedical Record Number: 1234567\\n\\nDiagnosis: Type 2 Diabetes Mellitus\\nInitial Assessment: Patient presented with symptoms of increased thirst and frequent urination. Blood glucose level was 250 mg/dL. Patient history includes family history of diabetes.\\n\\nTreatment Plan: Prescribed Metformin 500mg twice daily. Recommended dietary changes and increased physical activity. Follow-up appointment scheduled in 4 weeks.\\n\\nLab Results (Date: 2025-05-01):\\n- Fasting Glucose: 220 mg/dL (High)\\n- HbA1c: 9.5% (High)\\n- Cholesterol: 180 mg/dL (Normal)'),\n",
        "    #     Document(metadata={'page': '2', 'source': 'Medical_Report_PatientA.pdf', 'user': 'Dr. Smith'}, page_content='Progress Notes (Date: 2025-06-01):\\nPatient reports slight improvement in symptoms. Adherence to diet and exercise is moderate. Blood glucose today is 180 mg/dL. Continue Metformin. Emphasize importance of lifestyle changes. Schedule next follow-up in 8 weeks.'),\n",
        "    #     Document(metadata={'page': '1', 'source': 'Legal_Contract_CompanyX.pdf', 'user': 'Lawyer Jones'}, page_content='AGREEMENT made this 1st day of May, 2025, by and between Company X (\"Party A\") and Company Y (\"Party B\").\\n\\nWITNESSETH:\\nWHEREAS, Party A is engaged in the business of software development; and\\nWHEREAS, Party B desires to utilize Party A\\'s software development services.\\n\\nNOW, THEREFORE, in consideration of the mutual covenants contained herein, the parties agree as follows:\\n\\n1. Scope of Services. Party A shall provide software development services as detailed in Exhibit A, attached hereto and incorporated by reference.\\n\\n2. Payment Terms. Party B shall pay Party A a fee of $10,000 per month, due on the 15th day of each month. Late payments shall incur a penalty of 5% per month.\\n\\n3. Confidentiality. Both parties agree to maintain strict confidentiality regarding all information exchanged during the term of this agreement. This obligation shall survive the termination of the agreement for a period of five (5) years.'),\n",
        "    # ]\n",
        "\n",
        "    # # Example FAQ Documents\n",
        "    # faq_docs = [\n",
        "    #     Document(metadata={'source': 'Website_FAQ.txt', 'user': 'website_admin'}, page_content='Q: How do I reset my password?\\nA: To reset your password, click on the \"Forgot Password\" link on the login page. You will receive an email with instructions.'),\n",
        "    #     Document(metadata={'source': 'Website_FAQ.txt', 'user': 'website_admin'}, page_content='Q: What payment methods do you accept?\\nA: We accept Visa, Mastercard, American Express, and PayPal.'),\n",
        "    #     Document(metadata={'source': 'Product_FAQ.txt', 'user': 'product_support'}, page_content='Q: Is this product waterproof?\\nA: This product is water-resistant, but not fully waterproof. Avoid prolonged exposure to water.'),\n",
        "    # ]\n",
        "\n",
        "    legal_medical_docs=\"/content/pyspark.pdf\"\n",
        "\n",
        "    # Process and insert Legal/Medical documents\n",
        "    # process_legal_medical_records(client, legal_medical_docs, embedding_fn)\n",
        "\n",
        "    # Process and insert FAQ documents\n",
        "    process_faq_documents(client, legal_medical_docs, embedding_fn,'kartik')\n",
        "\n",
        "    # Example of retrieving content for a user (adapt query as needed)\n",
        "    # Note: This retrieval is based on vector similarity of a query embedding\n",
        "    # filtered by user, not a direct lookup of the original document content.\n",
        "    # You would typically search with a query relevant to the information you need.\n",
        "    # user_to_query = \"Dr. Smith\"\n",
        "    user_to_query = \"kartik\"\n",
        "    retrieved_content = get_content_by_user(client, user_to_query)\n",
        "\n",
        "    print(f\"\\nRetrieved content chunks for user '{user_to_query}':\")\n",
        "    if retrieved_content:\n",
        "        for item in retrieved_content:\n",
        "            print(f\"- Source: {item.get('source')}, Page: {item.get('original_page_number')}, User: {item.get('user')}\")\n",
        "            print(f\"  Content: {item.get('content_string')[:200]}...\") # Print first 200 chars\n",
        "            print(\"-\" * 10)\n",
        "    else:\n",
        "        print(\"No content found for this user based on the query.\")\n",
        "\n",
        "    # Close the client connection when done\n",
        "    # client.close() # MilvusClient in recent versions might not need explicit close for Lite\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymiMzl75kJNh",
        "outputId": "7629b33b-5c6b-4e3e-fe07-5772fe1bf315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collection 'rag_documents_nomic2' already exists.\n",
            "Index created on 'embedding' field (or already exists).\n",
            "\n",
            "--- Processing FAQ Documents ---\n",
            "Total chunks created for FAQ documents: 62\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-19 17:42:15,371 [ERROR][handler]: RPC error: [describe_collection], <DescribeCollectionException: (code=100, message=: collection not found)>, <Time:{'RPC start': '2025-05-19 17:42:15.369159', 'RPC error': '2025-05-19 17:42:15.371061'}> (decorators.py:140)\n",
            "2025-05-19 17:42:15,373 [ERROR][handler]: RPC error: [insert_rows], <DescribeCollectionException: (code=100, message=: collection not found)>, <Time:{'RPC start': '2025-05-19 17:42:15.369084', 'RPC error': '2025-05-19 17:42:15.373163'}> (decorators.py:140)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated embeddings for 62 chunks.\n",
            "Error during embedding or insertion: <DescribeCollectionException: (code=100, message=: collection not found)>\n",
            "--- Finished Processing FAQ Documents ---\n",
            "\n",
            "Retrieved content chunks for user 'kartik':\n",
            "No content found for this user based on the query.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = client.query(\n",
        "    collection_name=\"demo_collection\",\n",
        "    filter=\"subject == 'history'\",\n",
        "    output_fields=[\"text\", \"subject\"],\n",
        ")"
      ],
      "metadata": {
        "id": "lC_p_D1JrAcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\n\\n\".join([str(i) for i in\n",
        "                     client.query(collection_name=COLLECTION_NAME,data=[0,4],filter=' page_number == 1 ',output_fields=[\"page_number\",\"source\", \"content_string\",\"user\"],limit=2)\n",
        "                     ]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USGBgr_Bo8Y2",
        "outputId": "4ac19dce-b066-426d-ece5-75d702ef6026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'page_number': 1, 'content_string': 'Project Documentation: AI-Powered CV Parsing Microservice with Caching and AWS Translate  Objective: Develop an AI-powered CV parsing microservice that extracts data from user-uploaded CVs, maps the data to a predefined CandidateProfile schema, and stores it in MongoDB. The microservice must support multiple languages, cache parsed results for efficiency, provide error handling, and allow users to view their parsed CVs in both English and their preferred language.  Microservice Workflow Overview: 1. User Account Creation: Users create an account and select their preferred language. Before uploading a CV, users complete a series of tests and assessments to build their profile. 2. CV Upload and Parsing: Users upload their CVs in various formats (PDF, Word, Google Docs, etc.). The microservice parses the CV using AI/NLP services to extract key data such as personal information, experience, education, skills, and competencies.', 'source': 'TRIPA CV Parsing Project.pdf', 'user': 'kartik moyade'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVwojPgtWH0K",
        "outputId": "76a3672c-4763-4efc-dd77-cf465b50172b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "data: [\"{'page_number': 1, 'content_string': 'Project Documentation: AI-Powered CV Parsing Microservice with Caching and AWS Translate  Objective: Develop an AI-powered CV parsing microservice that extracts data from user-uploaded CVs, maps the data to a predefined CandidateProfile schema, and stores it in MongoDB. The microservice must support multiple languages, cache parsed results for efficiency, provide error handling, and allow users to view their parsed CVs in both English and their preferred language.  Microservice Workflow Overview: 1. User Account Creation: Users create an account and select their preferred language. Before uploading a CV, users complete a series of tests and assessments to build their profile. 2. CV Upload and Parsing: Users upload their CVs in various formats (PDF, Word, Google Docs, etc.). The microservice parses the CV using AI/NLP services to extract key data such as personal information, experience, education, skills, and competencies.', 'source': 'TRIPA CV Parsing Project.pdf', 'user': 'kartik moyade'}\", \"{'page_number': 2, 'content_string': 'Technological Stack: \\\\uf0a7 Backend Framework: Node.js (Express.js) \\\\uf0a7 Database: MongoDB (for storing candidate profile data) \\\\uf0a7 Caching: Centralized cache manager (cacheManager.js) \\\\uf0a7 NLP/AI: Third-party parsing services (e.g., Affinda) or custom NLP models \\\\uf0a7 Translation: AWS Translate (via translateUtils.js) \\\\uf0a7 Authentication & Security: Centralized and managed by TRIPA (e.g., JWT-based authentication, OAuth) \\\\uf0a7 Error Handling: handleError and logger utilities for centralized logging and error management \\\\uf0a7 Monitoring & Health Checks: Integrate monitoring tools and health check endpoints for real-time monitoring.  Additional Requirements for Robustness: 1. Failover and Resilience: \\\\uf0a7 In case of AI/NLP or translation service failure, fallback mechanisms must gracefully handle errors (e.g., log failures, notify users, and use default values where appropriate). ', 'source': 'TRIPA CV Parsing Project.pdf', 'user': 'kartik moyade'}\"]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "client.query(collection_name=COLLECTION_NAME,data=vectors,output_fields=[\"source\", \"content_string\",\"user\"],limit=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"Error Handling AI/NLP Authentication & Security\".lower()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "izAK0mmkwiDt",
        "outputId": "14b95e69-8098-42f1-eb63-4a568f03c81f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'error handling ai/nlp authentication & security'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fw3tATPvGIwV",
        "outputId": "f1722c54-2e80-4a91-c0d1-861983c4daeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'collection_name': 'rag_documents_nomic', 'auto_id': False, 'num_shards': 0, 'description': 'Collection for RAG documents with Nomic embeddings', 'fields': [{'field_id': 100, 'name': 'page_number', 'description': '', 'type': <DataType.INT64: 5>, 'params': {}, 'is_primary': True}, {'field_id': 101, 'name': 'source', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 256}}, {'field_id': 102, 'name': 'user', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 256}}, {'field_id': 103, 'name': 'content_string', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 4096}}, {'field_id': 104, 'name': 'embedding', 'description': '', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 768}}], 'functions': [], 'aliases': [], 'collection_id': 0, 'consistency_level': 0, 'properties': {}, 'num_partitions': 0, 'enable_dynamic_field': False}\n"
          ]
        }
      ],
      "source": [
        "collection_desc = client.describe_collection(\n",
        "    collection_name=COLLECTION_NAME\n",
        ")\n",
        "print(collection_desc)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client.search(\n",
        "    collection_name=COLLECTION_NAME,\n",
        "    data=vectors1,\n",
        "    filter=' user == \"kartik moyade\" ',\n",
        "    limit=1,\n",
        "    output_fields=[\"page_number\",\"source\", \"content_string\",\"user\"]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ludbpv73tp9L",
        "outputId": "ee6d65ba-fdbb-4e0c-8ab1-edf7086667d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "data: [[{'id': 1, 'distance': 0.0, 'entity': {'content_string': 'Project Documentation: AI-Powered CV Parsing Microservice with Caching and AWS Translate  Objective: Develop an AI-powered CV parsing microservice that extracts data from user-uploaded CVs, maps the data to a predefined CandidateProfile schema, and stores it in MongoDB. The microservice must support multiple languages, cache parsed results for efficiency, provide error handling, and allow users to view their parsed CVs in both English and their preferred language.  Microservice Workflow Overview: 1. User Account Creation: Users create an account and select their preferred language. Before uploading a CV, users complete a series of tests and assessments to build their profile. 2. CV Upload and Parsing: Users upload their CVs in various formats (PDF, Word, Google Docs, etc.). The microservice parses the CV using AI/NLP services to extract key data such as personal information, experience, education, skills, and competencies.', 'page_number': 1, 'source': 'TRIPA CV Parsing Project.pdf', 'user': 'kartik moyade'}}]]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdZOvG-2WKKT",
        "outputId": "1ce12d36-4070-43b3-b233-a91f47bfb3bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'collection_name': 'rag_documents_nomic2',\n",
              " 'auto_id': False,\n",
              " 'num_shards': 0,\n",
              " 'description': 'Collection for RAG documents with Nomic embeddings',\n",
              " 'fields': [{'field_id': 100,\n",
              "   'name': 'page_number',\n",
              "   'description': '',\n",
              "   'type': <DataType.INT64: 5>,\n",
              "   'params': {},\n",
              "   'is_primary': True},\n",
              "  {'field_id': 101,\n",
              "   'name': 'source',\n",
              "   'description': '',\n",
              "   'type': <DataType.VARCHAR: 21>,\n",
              "   'params': {'max_length': 256}},\n",
              "  {'field_id': 102,\n",
              "   'name': 'user',\n",
              "   'description': '',\n",
              "   'type': <DataType.VARCHAR: 21>,\n",
              "   'params': {'max_length': 256}},\n",
              "  {'field_id': 103,\n",
              "   'name': 'content_string',\n",
              "   'description': '',\n",
              "   'type': <DataType.VARCHAR: 21>,\n",
              "   'params': {'max_length': 4096}},\n",
              "  {'field_id': 104,\n",
              "   'name': 'embedding',\n",
              "   'description': '',\n",
              "   'type': <DataType.FLOAT_VECTOR: 101>,\n",
              "   'params': {'dim': 768}}],\n",
              " 'functions': [],\n",
              " 'aliases': [],\n",
              " 'collection_id': 0,\n",
              " 'consistency_level': 0,\n",
              " 'properties': {},\n",
              " 'num_partitions': 0,\n",
              " 'enable_dynamic_field': False}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.describe_collection(COLLECTION_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgZw_2p8U5gl"
      },
      "outputs": [],
      "source": [
        "from pymilvus import Collection\n",
        "coll=client.get_collection_stats(COLLECTION_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruKyfzuHAF_i",
        "outputId": "ed8818aa-ac8f-4698-9a5f-a846ee57f3d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'row_count': 6}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "coll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LoIB-gjYW8s"
      },
      "outputs": [],
      "source": [
        "res = client.search(\n",
        "    collection_name=\"demo_collection\",\n",
        "    data=embedding_fn.encode_queries([\"tell me AI related information\"]),\n",
        "    filter=\"user == 'kartik moyade'\",\n",
        "    limit=2,\n",
        "    output_fields=[\"text\", \"subject\"],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6Qx4X0QVXne",
        "outputId": "7c49f03d-3211-4b53-8a98-c2b23b3fc9bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collection 'rag_documents_nomic' already exists.\n"
          ]
        }
      ],
      "source": [
        "collection = client.load_collection(collection_name=COLLECTION_NAME)\n",
        "print(f\"Collection '{COLLECTION_NAME}' already exists.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzGTGZhXonks"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqTJ9VNQf6nY"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py &>/content/logs.txt &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RO4rDFCogett",
        "outputId": "00560b1a-7866-4fcd-994a-f0f2aabe9f82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0Kyour url is: https://tired-clubs-brake.loca.lt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRUDfsRnacVj",
        "outputId": "1d13e71a-758b-4de4-e7a8-24f655fd45d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\n",
            "\n",
            "  You can now view your Streamlit app in your browser.\n",
            "\n",
            "  Local URL: http://localhost:8502\n",
            "  Network URL: http://172.28.0.12:8502\n",
            "  External URL: http://34.118.242.43:8502\n",
            "\n",
            "  Stopping...\n",
            "49:36.143494: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744872576.167064   13373 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744872576.174162   13373 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Device set to use cuda:0\n",
            "  Stopping...\n"
          ]
        }
      ],
      "source": [
        "!cat /content/logs.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjCzSy8YYtNg",
        "outputId": "bf3b56a0-681b-4847-f7ee-503fec7d7e56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Password/Enpoint IP for localtunnel is: 34.118.242.43\n"
          ]
        }
      ],
      "source": [
        "import urllib\n",
        "print(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GbZijwwpF_J",
        "outputId": "24c2e9d9-cc8c-4e70-965a-7b9f5dc9a363"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import numpy\n",
        "import os\n",
        "import torch\n",
        "\n",
        "# Fix for \"Tried to instantiate class '__path__._path'\"\n",
        "torch.classes.__path__ = [os.path.join(os.path.dirname(torch.__file__), \"classes\")]\n",
        "from transformers import pipeline\n",
        "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress TensorFlow INFO/WARNING/ERROR logs\n",
        "os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/usr/local/cuda'  # Explicitly point to CUDA\n",
        "\n",
        "\n",
        "# --- Set up the HuggingFace pipeline ---\n",
        "@st.cache_resource(show_spinner=False)\n",
        "def load_pipeline():\n",
        "    pipe = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        device_map=\"auto\",\n",
        "        max_new_tokens=256,\n",
        "    )\n",
        "\n",
        "    # Set custom chat template\n",
        "    tinyllama_chat_template = (\n",
        "        \"\"\"\n",
        "{% for message in messages %}\n",
        "{% if message['role'] == 'user' %}\n",
        "{{ '<|user|>\n",
        "' + message['content'] + eos_token }}\n",
        "{% elif message['role'] == 'system' %}\n",
        "{{ '<|system|>\n",
        "' + message['content'] + eos_token }}\n",
        "{% elif message['role'] == 'assistant' %}\n",
        "{{ '<|assistant|>\n",
        "'  + message['content'] + eos_token }}\n",
        "{% endif %}\n",
        "{% if loop.last and add_generation_prompt %}\n",
        "{{ '<|assistant|>' }}\n",
        "{% endif %}\n",
        "{% endfor %}\n",
        "\"\"\"\n",
        "    )\n",
        "    try:\n",
        "        pipe.tokenizer.chat_template = tinyllama_chat_template\n",
        "    except AttributeError:\n",
        "        st.error(\"Failed to set chat template on tokenizer.\")\n",
        "\n",
        "    return pipe\n",
        "\n",
        "pipe = load_pipeline()\n",
        "hf = HuggingFacePipeline(pipeline=pipe)\n",
        "chat_model = ChatHuggingFace(llm=hf)\n",
        "\n",
        "st.set_page_config(page_title=\"TinyLlama Chat\", page_icon=\"🦙\")\n",
        "st.title(\"🦙 TinyLlama Chat App\")\n",
        "\n",
        "# Initialize chat history in session\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"}\n",
        "    ]\n",
        "\n",
        "# Display messages\n",
        "for msg in st.session_state.messages[1:]:\n",
        "    role = \"🧑\" if msg[\"role\"] == \"user\" else \"🤖\"\n",
        "    st.markdown(f\"**{role}**: {msg['content']}\")\n",
        "\n",
        "# Chat input\n",
        "user_input = st.chat_input(\"Ask me anything...\")\n",
        "if user_input:\n",
        "    # Append user message\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    # Format prompt using tokenizer’s chat template\n",
        "    formatted_prompt = pipe.tokenizer.apply_chat_template(\n",
        "        st.session_state.messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    # Generate response\n",
        "    with st.spinner(\"Thinking...\"):\n",
        "        response = chat_model.invoke(formatted_prompt)\n",
        "        content = response.content if hasattr(response, 'content') else str(response)\n",
        "\n",
        "    # Append AI response\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": content})\n",
        "    st.rerun()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaoEZfCOhPYB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388,
          "referenced_widgets": [
            "e8fd8a9fd7544177b96480b60329dcce",
            "51e732da7ed44721bf69057ce939e821",
            "fcc77baf5dee4e008583e6119f85977f",
            "1b412b6e56e34132b23441b849441c2b",
            "cd0ad009f98d4224b8df7b905212faff",
            "9d22f082f4c54be38bc40c4757d1ef64",
            "e256bac1da8547ed9c871a70eff45009",
            "e117bf7e19984910a3b52d5378205bc1",
            "4986c1b057d74bddabf62fe4e922ca73",
            "d454caa7f4c84e9dab5d54bad1ab04c2",
            "e0fdc13613444a32999a2f4222f47a5e",
            "c16de02134c6431b9befc1691c8f186c",
            "c62fb022f7c741c68677db362f151b31",
            "a2f84ac0b8d7498286b66678d7a72d2a",
            "ef0569eb09de4e02883478650144dedf",
            "8bd91434463d4c82a92be4b6d8805f5a",
            "b82aef59d5d44f979a4d51e710c3ab08",
            "bcd6a853511440d3b9c0f2fcc3ae26e5",
            "f74440a7bdcc4bfba33fafee36ab401f",
            "3f49735f5a514449ac0831978aa06ca2",
            "71a7d17dea5549479c24de89bfcf96db",
            "56f8d1dedc984c85beca5a64d7ec6517",
            "a681fa9f2e514cd48e623df7e0886765",
            "daabdfefdca84005b2012efa32a3d248",
            "2e85f9fe7d7d416a85447d8d99b5181b",
            "d65da9be5c284b88a5b5f6f98e5c48fe",
            "4c2b57e238cc4aa1aa96425256a8f1ae",
            "ce9aa53d49334748be772d0fa022c842",
            "c8a122a8b4a148c785c53a248c97b984",
            "cbdb49624f5e4e3383b0b5fdb8c063ad",
            "8013f5af09cd4f0b987498f13ca3aab2",
            "01f21506a3b84593b175880e2d70ab5c",
            "5dca920b7c2b438397b5f8e8a0937f96",
            "65d01b48bce84d73b71ba0a95aec29cf",
            "24cdb213c9c24f3daac9a351625bb153",
            "48baf2857f5d4040b66f33605a12ee4b",
            "bfc12bcdecb045fcb07ac51e6fb112df",
            "93aedc740645448f886b21c4ef90928b",
            "c82afc29f0c241dfaa45ff2c1883ce87",
            "1c1e1548dedb47c980f1ae7179011d2d",
            "1f2c83eb621940f78666dd09c076449d",
            "ec6827d2cffb4df5abd63e10c4d15dd9",
            "ee9ababc43dd4e93bb7e0f39b6d63a51",
            "00904612d028461a91bd3f7dd51cb757",
            "6d92fb5d7fa745399841b10938405424",
            "4c7826c89b7a43adac5fa31dd85761b8",
            "3585f6106a6849b9bb58a044eb56e3fd",
            "63707cb81ebc43b89438e705537ed626",
            "9dc678d2bf3d46fb99e06b05e8f43766",
            "93f2a7c54b8046248a80f039ac6cdc23",
            "a98a75ff590b4080b98d7d72ae221aee",
            "aa86b5ed9fa949d2aaeb07d7ac7b5493",
            "b8814e571fd04f96a5764fafec3af9d2",
            "ab4d57fea8a94e20947d46daeefb08c4",
            "d045c70b9f2545889e77258c2faacb9d",
            "ec50789f78004394b63fe49cd36a44a3",
            "23d87a1cf5fd4f8b84df9596e3577a0f",
            "b70b5e3fa6d3466eb762538b3e8d4226",
            "94f5296d0af04a6ca757a3e779a4a6ee",
            "08b354b871624332a0656b26b203dc53",
            "fd5b6c7fa8534dab9ca787ecede565f6",
            "bb680b9850f244888178dba92c9a17f6",
            "835dbc5f9fbc40d79d6c61a32af180e4",
            "5c8fa9923e2c436697df5514f651f006",
            "e1ac411b3ef0478fbbfe10eb0a0735d0",
            "4178675b94d448f6bcf9e8879d237d6b",
            "8c10f05995e64991b64655475dc362b9",
            "1c4c9143abfc4f44b5b0dc878ac7569e",
            "1042462e2baf44c282b8f56bdc4af57e",
            "9230a2e88ff14afabc77cee2e0e9d45d",
            "bec258cb2ade4f6eadfd98ca81ed7c23",
            "a1cf70183ebc41aaac9a0f501c14aa3d",
            "58dc87bcd564489c991bb13834503380",
            "1bc37cd9859a4173835c388930121473",
            "5312be30b6f54d39a1fef2c70bc6aefe",
            "ec05128991204d6797674b87bd3de7ff",
            "d12b852808a94244bde6ac86f53a848b"
          ]
        },
        "outputId": "1b9fd276-5df5-401c-e2e0-82f415acb80d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8fd8a9fd7544177b96480b60329dcce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c16de02134c6431b9befc1691c8f186c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a681fa9f2e514cd48e623df7e0886765"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "65d01b48bce84d73b71ba0a95aec29cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d92fb5d7fa745399841b10938405424"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec50789f78004394b63fe49cd36a44a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c10f05995e64991b64655475dc362b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "import torch\n",
        "\n",
        "def load_pipeline():\n",
        "    pipe = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        device_map=\"auto\",\n",
        "        max_new_tokens=256,\n",
        "    )\n",
        "\n",
        "    # Set custom chat template\n",
        "    tinyllama_chat_template = (\n",
        "        \"\"\"\n",
        "{% for message in messages %}\n",
        "{% if message['role'] == 'user' %}\n",
        "{{ '<|user|>\n",
        "' + message['content'] + eos_token }}\n",
        "{% elif message['role'] == 'system' %}\n",
        "{{ '<|system|>\n",
        "' + message['content'] + eos_token }}\n",
        "{% elif message['role'] == 'assistant' %}\n",
        "{{ '<|assistant|>\n",
        "'  + message['content'] + eos_token }}\n",
        "{% endif %}\n",
        "{% if loop.last and add_generation_prompt %}\n",
        "{{ '<|assistant|>' }}\n",
        "{% endif %}\n",
        "{% endfor %}\n",
        "\"\"\"\n",
        "    )\n",
        "    try:\n",
        "        pipe.tokenizer.chat_template = tinyllama_chat_template\n",
        "    except AttributeError:\n",
        "        st.error(\"Failed to set chat template on tokenizer.\")\n",
        "\n",
        "    return pipe\n",
        "\n",
        "pipe = load_pipeline()\n",
        "hf = HuggingFacePipeline(pipeline=pipe)\n",
        "chat_model = ChatHuggingFace(llm=hf)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# {\"role\": \"user\", \"content\": user_input}\n",
        "\n",
        "    # Format prompt using tokenizer’s chat template\n",
        "formatted_prompt = pipe.tokenizer.apply_chat_template(\n",
        "    [{\"role\": \"user\", \"content\": \"what is earth made of?\"}],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "response = chat_model.invoke(formatted_prompt)"
      ],
      "metadata": {
        "id": "Jh8QclNQScy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\".join(map(str.lstrip(\" \"),response.content.lstrip('<|assistant|>')[2].split(\".\"))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "a2wJeYmeVYoN",
        "outputId": "3b6b7d4b-66f5-451c-a7f6-83abce1e514c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'str' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-b02e237d1684>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<|assistant|>'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"fsdfsdfds dfsdfdsf jdnjsnd\".lstrip(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jcYab9y2VlGu",
        "outputId": "bcca539f-7fdb-42dd-8fed-17cc7134630e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sdfsdfds dfsdfdsf jdnjsnd'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "map(str.lstrip(\" \"),response.content.split('<|assistant|>')[2].split(\".\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "a-nLE2Mza8sN",
        "outputId": "0ef4eea1-ed28-449f-ab8d-25e77fa61a0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'str' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-b3f89f2c17ec>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<|assistant|>'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' It is made up of a core made of iron and nickel, a mantle made of molten rock, and a crust made of rock and minerals'.lstrip(\" \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jgCuZaXnstZO",
        "outputId": "214d7ede-d405-4e5e-d6a4-f4c7e281ca76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'It is made up of a core made of iron and nickel, a mantle made of molten rock, and a crust made of rock and minerals'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_parts = [part.lstrip(\" \") for part in response.content.split('<|assistant|>')[-1].split(\".\") if part.strip()]"
      ],
      "metadata": {
        "id": "v7T6HUPqtK-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\".join(processed_parts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69X72hzst6v9",
        "outputId": "76cd4fa6-d8d4-4522-f0ef-9cb1f185dbd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Earth is a rocky, solid, and planetary body that orbits the Sun in the solar system\n",
            "It is made up of a core made of iron and nickel, a mantle made of molten rock, and a crust made of rock and minerals\n",
            "The crust is made up of rocks such as granite, basalt, and sedimentary rocks, while the mantle is made up of molten rock that is deep beneath the crust\n",
            "The core is made up of a solid iron and nickel core that is surrounded by a liquid outer core\n",
            "The outer core is made up of iron and nickel, while the inner core is made up of a solid iron and nickel core surrounded by a liquid outer core\n",
            "Earth's magnetic field is generated by the movement of its core, which generates a magnetic field that surrounds the planet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zEFgdFqpt_EW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e8fd8a9fd7544177b96480b60329dcce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51e732da7ed44721bf69057ce939e821",
              "IPY_MODEL_fcc77baf5dee4e008583e6119f85977f",
              "IPY_MODEL_1b412b6e56e34132b23441b849441c2b"
            ],
            "layout": "IPY_MODEL_cd0ad009f98d4224b8df7b905212faff"
          }
        },
        "51e732da7ed44721bf69057ce939e821": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d22f082f4c54be38bc40c4757d1ef64",
            "placeholder": "​",
            "style": "IPY_MODEL_e256bac1da8547ed9c871a70eff45009",
            "value": "config.json: 100%"
          }
        },
        "fcc77baf5dee4e008583e6119f85977f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e117bf7e19984910a3b52d5378205bc1",
            "max": 608,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4986c1b057d74bddabf62fe4e922ca73",
            "value": 608
          }
        },
        "1b412b6e56e34132b23441b849441c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d454caa7f4c84e9dab5d54bad1ab04c2",
            "placeholder": "​",
            "style": "IPY_MODEL_e0fdc13613444a32999a2f4222f47a5e",
            "value": " 608/608 [00:00&lt;00:00, 13.8kB/s]"
          }
        },
        "cd0ad009f98d4224b8df7b905212faff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d22f082f4c54be38bc40c4757d1ef64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e256bac1da8547ed9c871a70eff45009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e117bf7e19984910a3b52d5378205bc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4986c1b057d74bddabf62fe4e922ca73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d454caa7f4c84e9dab5d54bad1ab04c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0fdc13613444a32999a2f4222f47a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c16de02134c6431b9befc1691c8f186c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c62fb022f7c741c68677db362f151b31",
              "IPY_MODEL_a2f84ac0b8d7498286b66678d7a72d2a",
              "IPY_MODEL_ef0569eb09de4e02883478650144dedf"
            ],
            "layout": "IPY_MODEL_8bd91434463d4c82a92be4b6d8805f5a"
          }
        },
        "c62fb022f7c741c68677db362f151b31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b82aef59d5d44f979a4d51e710c3ab08",
            "placeholder": "​",
            "style": "IPY_MODEL_bcd6a853511440d3b9c0f2fcc3ae26e5",
            "value": "model.safetensors: 100%"
          }
        },
        "a2f84ac0b8d7498286b66678d7a72d2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f74440a7bdcc4bfba33fafee36ab401f",
            "max": 2200119864,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f49735f5a514449ac0831978aa06ca2",
            "value": 2200119864
          }
        },
        "ef0569eb09de4e02883478650144dedf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71a7d17dea5549479c24de89bfcf96db",
            "placeholder": "​",
            "style": "IPY_MODEL_56f8d1dedc984c85beca5a64d7ec6517",
            "value": " 2.20G/2.20G [00:21&lt;00:00, 44.4MB/s]"
          }
        },
        "8bd91434463d4c82a92be4b6d8805f5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b82aef59d5d44f979a4d51e710c3ab08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcd6a853511440d3b9c0f2fcc3ae26e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f74440a7bdcc4bfba33fafee36ab401f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f49735f5a514449ac0831978aa06ca2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71a7d17dea5549479c24de89bfcf96db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56f8d1dedc984c85beca5a64d7ec6517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a681fa9f2e514cd48e623df7e0886765": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_daabdfefdca84005b2012efa32a3d248",
              "IPY_MODEL_2e85f9fe7d7d416a85447d8d99b5181b",
              "IPY_MODEL_d65da9be5c284b88a5b5f6f98e5c48fe"
            ],
            "layout": "IPY_MODEL_4c2b57e238cc4aa1aa96425256a8f1ae"
          }
        },
        "daabdfefdca84005b2012efa32a3d248": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce9aa53d49334748be772d0fa022c842",
            "placeholder": "​",
            "style": "IPY_MODEL_c8a122a8b4a148c785c53a248c97b984",
            "value": "generation_config.json: 100%"
          }
        },
        "2e85f9fe7d7d416a85447d8d99b5181b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbdb49624f5e4e3383b0b5fdb8c063ad",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8013f5af09cd4f0b987498f13ca3aab2",
            "value": 124
          }
        },
        "d65da9be5c284b88a5b5f6f98e5c48fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01f21506a3b84593b175880e2d70ab5c",
            "placeholder": "​",
            "style": "IPY_MODEL_5dca920b7c2b438397b5f8e8a0937f96",
            "value": " 124/124 [00:00&lt;00:00, 9.35kB/s]"
          }
        },
        "4c2b57e238cc4aa1aa96425256a8f1ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce9aa53d49334748be772d0fa022c842": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8a122a8b4a148c785c53a248c97b984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbdb49624f5e4e3383b0b5fdb8c063ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8013f5af09cd4f0b987498f13ca3aab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "01f21506a3b84593b175880e2d70ab5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dca920b7c2b438397b5f8e8a0937f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65d01b48bce84d73b71ba0a95aec29cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24cdb213c9c24f3daac9a351625bb153",
              "IPY_MODEL_48baf2857f5d4040b66f33605a12ee4b",
              "IPY_MODEL_bfc12bcdecb045fcb07ac51e6fb112df"
            ],
            "layout": "IPY_MODEL_93aedc740645448f886b21c4ef90928b"
          }
        },
        "24cdb213c9c24f3daac9a351625bb153": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c82afc29f0c241dfaa45ff2c1883ce87",
            "placeholder": "​",
            "style": "IPY_MODEL_1c1e1548dedb47c980f1ae7179011d2d",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "48baf2857f5d4040b66f33605a12ee4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f2c83eb621940f78666dd09c076449d",
            "max": 1289,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec6827d2cffb4df5abd63e10c4d15dd9",
            "value": 1289
          }
        },
        "bfc12bcdecb045fcb07ac51e6fb112df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee9ababc43dd4e93bb7e0f39b6d63a51",
            "placeholder": "​",
            "style": "IPY_MODEL_00904612d028461a91bd3f7dd51cb757",
            "value": " 1.29k/1.29k [00:00&lt;00:00, 72.1kB/s]"
          }
        },
        "93aedc740645448f886b21c4ef90928b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c82afc29f0c241dfaa45ff2c1883ce87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c1e1548dedb47c980f1ae7179011d2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f2c83eb621940f78666dd09c076449d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec6827d2cffb4df5abd63e10c4d15dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee9ababc43dd4e93bb7e0f39b6d63a51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00904612d028461a91bd3f7dd51cb757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d92fb5d7fa745399841b10938405424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c7826c89b7a43adac5fa31dd85761b8",
              "IPY_MODEL_3585f6106a6849b9bb58a044eb56e3fd",
              "IPY_MODEL_63707cb81ebc43b89438e705537ed626"
            ],
            "layout": "IPY_MODEL_9dc678d2bf3d46fb99e06b05e8f43766"
          }
        },
        "4c7826c89b7a43adac5fa31dd85761b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93f2a7c54b8046248a80f039ac6cdc23",
            "placeholder": "​",
            "style": "IPY_MODEL_a98a75ff590b4080b98d7d72ae221aee",
            "value": "tokenizer.model: 100%"
          }
        },
        "3585f6106a6849b9bb58a044eb56e3fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa86b5ed9fa949d2aaeb07d7ac7b5493",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b8814e571fd04f96a5764fafec3af9d2",
            "value": 499723
          }
        },
        "63707cb81ebc43b89438e705537ed626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab4d57fea8a94e20947d46daeefb08c4",
            "placeholder": "​",
            "style": "IPY_MODEL_d045c70b9f2545889e77258c2faacb9d",
            "value": " 500k/500k [00:00&lt;00:00, 36.7MB/s]"
          }
        },
        "9dc678d2bf3d46fb99e06b05e8f43766": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93f2a7c54b8046248a80f039ac6cdc23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a98a75ff590b4080b98d7d72ae221aee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa86b5ed9fa949d2aaeb07d7ac7b5493": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8814e571fd04f96a5764fafec3af9d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab4d57fea8a94e20947d46daeefb08c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d045c70b9f2545889e77258c2faacb9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec50789f78004394b63fe49cd36a44a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23d87a1cf5fd4f8b84df9596e3577a0f",
              "IPY_MODEL_b70b5e3fa6d3466eb762538b3e8d4226",
              "IPY_MODEL_94f5296d0af04a6ca757a3e779a4a6ee"
            ],
            "layout": "IPY_MODEL_08b354b871624332a0656b26b203dc53"
          }
        },
        "23d87a1cf5fd4f8b84df9596e3577a0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd5b6c7fa8534dab9ca787ecede565f6",
            "placeholder": "​",
            "style": "IPY_MODEL_bb680b9850f244888178dba92c9a17f6",
            "value": "tokenizer.json: 100%"
          }
        },
        "b70b5e3fa6d3466eb762538b3e8d4226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_835dbc5f9fbc40d79d6c61a32af180e4",
            "max": 1842767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c8fa9923e2c436697df5514f651f006",
            "value": 1842767
          }
        },
        "94f5296d0af04a6ca757a3e779a4a6ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1ac411b3ef0478fbbfe10eb0a0735d0",
            "placeholder": "​",
            "style": "IPY_MODEL_4178675b94d448f6bcf9e8879d237d6b",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 8.64MB/s]"
          }
        },
        "08b354b871624332a0656b26b203dc53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd5b6c7fa8534dab9ca787ecede565f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb680b9850f244888178dba92c9a17f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "835dbc5f9fbc40d79d6c61a32af180e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c8fa9923e2c436697df5514f651f006": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1ac411b3ef0478fbbfe10eb0a0735d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4178675b94d448f6bcf9e8879d237d6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c10f05995e64991b64655475dc362b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c4c9143abfc4f44b5b0dc878ac7569e",
              "IPY_MODEL_1042462e2baf44c282b8f56bdc4af57e",
              "IPY_MODEL_9230a2e88ff14afabc77cee2e0e9d45d"
            ],
            "layout": "IPY_MODEL_bec258cb2ade4f6eadfd98ca81ed7c23"
          }
        },
        "1c4c9143abfc4f44b5b0dc878ac7569e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1cf70183ebc41aaac9a0f501c14aa3d",
            "placeholder": "​",
            "style": "IPY_MODEL_58dc87bcd564489c991bb13834503380",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "1042462e2baf44c282b8f56bdc4af57e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bc37cd9859a4173835c388930121473",
            "max": 551,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5312be30b6f54d39a1fef2c70bc6aefe",
            "value": 551
          }
        },
        "9230a2e88ff14afabc77cee2e0e9d45d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec05128991204d6797674b87bd3de7ff",
            "placeholder": "​",
            "style": "IPY_MODEL_d12b852808a94244bde6ac86f53a848b",
            "value": " 551/551 [00:00&lt;00:00, 27.5kB/s]"
          }
        },
        "bec258cb2ade4f6eadfd98ca81ed7c23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1cf70183ebc41aaac9a0f501c14aa3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58dc87bcd564489c991bb13834503380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bc37cd9859a4173835c388930121473": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5312be30b6f54d39a1fef2c70bc6aefe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec05128991204d6797674b87bd3de7ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d12b852808a94244bde6ac86f53a848b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0dbd91b4b66457f97d0873d73bd83da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e17ddbbea1014ab9898b60405db11abd",
              "IPY_MODEL_542436179cca4a5699ccb1d05818cf98",
              "IPY_MODEL_3ab6138432dd4021806ac8464879fdff"
            ],
            "layout": "IPY_MODEL_d777bc0c95584e8e8ac4e488d455afc7"
          }
        },
        "e17ddbbea1014ab9898b60405db11abd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fa7423fb608479582bd79a3d34117b1",
            "placeholder": "​",
            "style": "IPY_MODEL_a8e5012eb251486b9a7eff70dc2a7368",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "542436179cca4a5699ccb1d05818cf98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ed23936b7ab4f748e4e3bba3ef37b62",
            "max": 465,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a498a58571374fc9b28a2be66a8a5b02",
            "value": 465
          }
        },
        "3ab6138432dd4021806ac8464879fdff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc3f866575a045649befa64b29c4cf26",
            "placeholder": "​",
            "style": "IPY_MODEL_0f4dc53ac3a04616b3c70c3b63b0b691",
            "value": " 465/465 [00:00&lt;00:00, 17.3kB/s]"
          }
        },
        "d777bc0c95584e8e8ac4e488d455afc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fa7423fb608479582bd79a3d34117b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8e5012eb251486b9a7eff70dc2a7368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ed23936b7ab4f748e4e3bba3ef37b62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a498a58571374fc9b28a2be66a8a5b02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc3f866575a045649befa64b29c4cf26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f4dc53ac3a04616b3c70c3b63b0b691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "770a89bb35b54dc49c7e8c7e73fb3cc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25425ba4f50f479fa1889554fa0e3a80",
              "IPY_MODEL_cacfbc0407364cd98723d0aa551f566c",
              "IPY_MODEL_e53d90e5121e461f9e9a3d723d1ef75a"
            ],
            "layout": "IPY_MODEL_58da9256a7a545d79ab0ba81074e2cd3"
          }
        },
        "25425ba4f50f479fa1889554fa0e3a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0cca9fdffae403f9239391b87050ea9",
            "placeholder": "​",
            "style": "IPY_MODEL_46ba0ae73a2b487bb288847e776d4cbe",
            "value": "config.json: 100%"
          }
        },
        "cacfbc0407364cd98723d0aa551f566c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f06cfe6b4bdc458fb97731faf93209dc",
            "max": 827,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d22bb65f73a4e119a04bd1c7d51e149",
            "value": 827
          }
        },
        "e53d90e5121e461f9e9a3d723d1ef75a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5cd29ea3e0e4a0e9f3459391f053df9",
            "placeholder": "​",
            "style": "IPY_MODEL_28f44feff17647c6869302fe18b6aedc",
            "value": " 827/827 [00:00&lt;00:00, 59.8kB/s]"
          }
        },
        "58da9256a7a545d79ab0ba81074e2cd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0cca9fdffae403f9239391b87050ea9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46ba0ae73a2b487bb288847e776d4cbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f06cfe6b4bdc458fb97731faf93209dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d22bb65f73a4e119a04bd1c7d51e149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5cd29ea3e0e4a0e9f3459391f053df9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28f44feff17647c6869302fe18b6aedc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa79f234757e4f7abdb951f52a44e318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b567fe0acce45e89735402beb24aa38",
              "IPY_MODEL_cba74810a01c4f23af340ce575ff90f9",
              "IPY_MODEL_d601b0e6158543be856eb435f8b50f74"
            ],
            "layout": "IPY_MODEL_209f0e836a594c30abedc451c0262000"
          }
        },
        "1b567fe0acce45e89735402beb24aa38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eff5a5c9a73845e4a0a9f2abe19d35de",
            "placeholder": "​",
            "style": "IPY_MODEL_74da144c12a24216b54dff8e885b7343",
            "value": "spiece.model: 100%"
          }
        },
        "cba74810a01c4f23af340ce575ff90f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53c5b93eef9b4f1eb9ba6591ac082f52",
            "max": 760289,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e37ab95168f4e189093b6a9c2a792a2",
            "value": 760289
          }
        },
        "d601b0e6158543be856eb435f8b50f74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95ccc27890704a528ef6a0d84e9bf755",
            "placeholder": "​",
            "style": "IPY_MODEL_e8ec1594354f47c696aa5fdc64ce49e1",
            "value": " 760k/760k [00:00&lt;00:00, 8.10MB/s]"
          }
        },
        "209f0e836a594c30abedc451c0262000": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eff5a5c9a73845e4a0a9f2abe19d35de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74da144c12a24216b54dff8e885b7343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53c5b93eef9b4f1eb9ba6591ac082f52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e37ab95168f4e189093b6a9c2a792a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "95ccc27890704a528ef6a0d84e9bf755": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8ec1594354f47c696aa5fdc64ce49e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90ad0dd329234b718113b02c2d0038b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4fa40c73ae6548598427f19ac176586e",
              "IPY_MODEL_97ff00e97a2847e7879d34dfe214bf41",
              "IPY_MODEL_829dfb0d417441b491a4a8d25d399197"
            ],
            "layout": "IPY_MODEL_79e0f3da7b324ecda659fe912b712432"
          }
        },
        "4fa40c73ae6548598427f19ac176586e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34112cf4b6dc4c228faa779576046a39",
            "placeholder": "​",
            "style": "IPY_MODEL_0e6c821400ba4c348b689264d8663645",
            "value": "tokenizer.json: 100%"
          }
        },
        "97ff00e97a2847e7879d34dfe214bf41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_daa6b14db6184827b5861734791f338e",
            "max": 1311010,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b3adcec973142be90b634118b24a58f",
            "value": 1311010
          }
        },
        "829dfb0d417441b491a4a8d25d399197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae721a4a167240b1bbdf157893d2cb5b",
            "placeholder": "​",
            "style": "IPY_MODEL_d0bc52dde2f64e40a30db5833d825d1e",
            "value": " 1.31M/1.31M [00:00&lt;00:00, 20.5MB/s]"
          }
        },
        "79e0f3da7b324ecda659fe912b712432": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34112cf4b6dc4c228faa779576046a39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e6c821400ba4c348b689264d8663645": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "daa6b14db6184827b5861734791f338e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b3adcec973142be90b634118b24a58f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae721a4a167240b1bbdf157893d2cb5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0bc52dde2f64e40a30db5833d825d1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55c517b38d134ccc9b8ac1cbd52baa57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be5ead46a2a34c98a545df8899832692",
              "IPY_MODEL_a80f87e57229423aaccec53629d1b33c",
              "IPY_MODEL_dfd50c6966e14e36afdb4a1767c87934"
            ],
            "layout": "IPY_MODEL_324ea00ffe844f5da191474e4bcb3048"
          }
        },
        "be5ead46a2a34c98a545df8899832692": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12def2f7d2ce4e3684f3eb84b988580e",
            "placeholder": "​",
            "style": "IPY_MODEL_35b0fa27a2794c15b3c19edc9a3ee075",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "a80f87e57229423aaccec53629d1b33c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f969462f8f6646c695782147c4233e4b",
            "max": 245,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ee50c5b76604b1ba77206294cc294f3",
            "value": 245
          }
        },
        "dfd50c6966e14e36afdb4a1767c87934": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a676ecf11fae494ca586ac8c5e5b015e",
            "placeholder": "​",
            "style": "IPY_MODEL_444a50f6507c40739ec9cc496b5a44fc",
            "value": " 245/245 [00:00&lt;00:00, 13.4kB/s]"
          }
        },
        "324ea00ffe844f5da191474e4bcb3048": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12def2f7d2ce4e3684f3eb84b988580e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35b0fa27a2794c15b3c19edc9a3ee075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f969462f8f6646c695782147c4233e4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ee50c5b76604b1ba77206294cc294f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a676ecf11fae494ca586ac8c5e5b015e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "444a50f6507c40739ec9cc496b5a44fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b25b9f5d0087456abf9b0055954ec4a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dfb548c126ca4362a15962098693baa2",
              "IPY_MODEL_b4ec4f40edfe416eb9a9f6b521fc8f56",
              "IPY_MODEL_8e92318390d84338a0cfe6ebfb5cd4f2"
            ],
            "layout": "IPY_MODEL_f49e63651940457280fa268915749ac3"
          }
        },
        "dfb548c126ca4362a15962098693baa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_436e66cb9594424abde9c348c412061f",
            "placeholder": "​",
            "style": "IPY_MODEL_2e43760a1aee42149e7e1d5c9adbc63b",
            "value": "model.onnx: 100%"
          }
        },
        "b4ec4f40edfe416eb9a9f6b521fc8f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd223c5c95224226ba65f83639e71f39",
            "max": 46865550,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da5d92f5d9b84ad79dbdc56e12e2a75d",
            "value": 46865550
          }
        },
        "8e92318390d84338a0cfe6ebfb5cd4f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bca69c76b5e44c5b8e292b6115c72ff",
            "placeholder": "​",
            "style": "IPY_MODEL_5e0e85e8a7ff4e39acdd48935f8bbfe7",
            "value": " 46.9M/46.9M [00:00&lt;00:00, 113MB/s]"
          }
        },
        "f49e63651940457280fa268915749ac3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "436e66cb9594424abde9c348c412061f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e43760a1aee42149e7e1d5c9adbc63b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd223c5c95224226ba65f83639e71f39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da5d92f5d9b84ad79dbdc56e12e2a75d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4bca69c76b5e44c5b8e292b6115c72ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e0e85e8a7ff4e39acdd48935f8bbfe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}